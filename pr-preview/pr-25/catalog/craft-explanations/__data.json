{"type":"data","nodes":[null,{"type":"data","data":[{"extension":1},{"slug":2,"kind":3,"manifest":4,"tagline":19,"readme":20,"components":21,"variant":24,"tags":11,"docs":25,"docCount":37},"craft-explanations","plugin",{"name":2,"version":5,"description":6,"author":7,"license":10,"keywords":11},"0.2.0","Explanation craft through simultaneous encoding. Use when: writing docs, explaining concepts, teaching in conversation, creating tutorials, curating documentation collections, making diagrams for explanation (Mermaid, D2, C4).",{"name":8,"email":9},"Mox Labs","mox.rnd@gmail.com","MIT",[12,13,14,15,16,17,18],"explanations","documentation","teaching","diagrams","visual-communication","information-architecture","pedagogy","Explanation craft through simultaneous encoding. Part of the cix marketplace.","# craft-explanations\n\nExplanation craft through simultaneous encoding. Part of the cix marketplace.\n\n## What This Plugin Does\n\nHelps Claude write explanations that carry all three doors simultaneously — principle, concretions, and ground — so the receiver pulls what they need rather than being forced through a prescribed sequence.\n\n## The Three Doors\n\n| Door | Explanation | Engineering | Philosophy |\n|------|-------------|-------------|------------|\n| **1** | Principle | Abstraction | Universal |\n| **2** | Concretions | Planning | Constituency |\n| **3** | Ground | Execution | Self |\n\n## Skills\n\n| Skill | Purpose |\n|-------|---------|\n| **craft-explanations** | Three Doors encoding, modal lock diagnosis, explanation routing |\n| **weaving** | Re-weave modal-locked content across all three doors |\n| **visual-communication** | Diagram type selection (Mermaid, D2, C4), visual explanation design |\n| **information-architecture** | Collection-level structure, single source of truth, layer model |\n\n## Agents\n\n| Agent | Entry Door | Best For |\n|-------|-----------|----------|\n| **feynman** | Door 3 (Ground · Execution · Self) | Docs, tutorials, teaching |\n| **sagan** | Door 1 (Principle · Abstraction · Universal) | Vision docs, concept overviews |\n| **tufte** | Door 2 (Concretions · Planning · Constituency) | Diagram decisions, data explanation |\n| **socrates** | Forces traversal across all doors | Reviewing explanations, deepening understanding |\n\n## Design Philosophy\n\nSee `docs/explanation/methodology.md` for the full rationale. Key points:\n\n- **Three Doors** — principle, concretions, and ground as simultaneous dimensions, not sequential layers\n- **Directional modal lock** — shifts go through the next door (1→2→3), not a skip\n- **Wider, not louder** — encode all three doors so signal survives lossy compression\n- **Dimensional shift** — the most powerful moments happen when understanding crosses doors\n- **Constituency is the bridge** — you can't reach Self without passing through Constituency\n",{"agents":22,"skills":22,"hooks":23,"commands":23},4,0,"spark",{"explanation":26,"how-to":35,"tutorials":36},[27,31],{"slug":28,"title":29,"content":30},"methodology","Craft Explanations: Design Methodology","# Craft Explanations: Design Methodology\n\nThis document explains WHY the craft-explanations plugin is designed the way it is.\n\n## The Core Insight: The Three Doors\n\nExplanations aren't sequential layers (principle → pattern → practice). They're fabric with three simultaneous dimensions — a coordinate system, not a ladder.\n\nThree dimensions of perception, not a hierarchy:\n\n- **Coherence** — the unifying principle, why this holds together\n- **Contrast** — the alternatives weighed, why this and not that\n- **Ground** — the weight that doesn't argue for itself, what is right now\n\n### The Facet-Set Model\n\nEach door isn't a single concept. It's a facet set — the same dimension viewed from different domains:\n\n| Door | Explanation | Engineering | Philosophy |\n|------|-------------|-------------|------------|\n| **1** | Principle | Abstraction | Universal |\n| **2** | Concretions | Planning | Constituency |\n| **3** | Ground | Execution | Self |\n\nThe vertical alignment is the same dimension through different lenses. The horizontal flow narrows: Universal → Constituency → Self.\n\n- Door 1 is true everywhere, no context needed\n- Door 2 is true for these people, in this situation — it requires knowing who's in the room\n- Door 3 is true for me, right now, in my hands — it requires the body\n\n**Constituency is the bridge.** The abstract becomes concrete *for someone*. Skip Door 2 and Door 3 becomes generic steps. You can't jump from Universal to Self without passing through Constituency.\n\n### Evolution from v0.1\n\nThe original skill used Principle / Pattern / Practice as the three labels. This was replaced in v0.2 because:\n\n- **\"Pattern\"** was the weakest name. It doesn't communicate that Door 2 is about *who this is for* — the constituency, the concretion for a specific audience. \"Pattern\" sounds like taxonomy. \"Concretions\" says the universal truth has been shaped for someone particular.\n- **\"Practice\"** was too generic. \"Just add a practical example\" can still be abstract — a hypothetical scenario, a generic code sample. That's Door 1 wearing Door 3's clothes. \"Ground\" conveys weight, embodiment, the thing that doesn't argue for itself because it doesn't need to.\n- **The facet sets** reveal that the three doors aren't explanation-specific. They map onto engineering (Abstraction → Planning → Execution), philosophy (Universal → Constituency → Self), and architecture (Domain model → Application layer → Infrastructure). The framework is a coordinate system that applies across domains.\n\n## Why Directional Modal Lock\n\nv0.1 diagnosed modal lock as \"you're stuck in one dimension, shift to another.\" v0.2 adds directionality: shifts go through the next door (1→2→3), not a skip.\n\nThis matters because:\n- Jumping from Door 1 (beautiful framework) directly to Door 3 (steps) without Door 2 (who is this for?) produces generic instructions that look practical but aren't grounded in anyone's reality\n- Door 2 is the bridge that gets skipped most often — especially by Claude, whose default lock is Abstraction | Universal\n- The directional diagnosis tells you *which* shift to make, not just that one is needed\n\n## Why Dimensional Shift\n\nThe most powerful learning moments happen at intersections between doors — when understanding crosses from one dimension to another. \"I understood it, then suddenly I *felt* it\" (Door 1 → Door 3). \"I iterated, then it settled into my hands\" (Door 2 → Door 3).\n\nThis goes beyond \"all three doors should be present\" to: **design the transitions between them**. The moment of crossing is where information becomes knowledge.\n\n## Why \"Wider, Not Louder\"\n\nWhen explanation fails, the instinct is to amplify: more docs, more slides, more energy. This deepens modal lock.\n\nThe reframe: explanation failure is dimensional compression across instrumental boundaries. Each receiver — each organizational layer — compresses through whatever dimensions it can perceive. The fix isn't louder signal. It's wider encoding — all three doors woven so that enough survives in whatever dimension the receiver can pass.\n\nThis connects to the interpretability insight: the meeting problem (human → human) and the interpretability problem (model → human) may be the same dimensional compression problem viewed from opposite directions.\n\n## Why Four Agents with Different Entry Doors\n\nInitial design mapped agents 1:1 to dimensions. This was rejected because it decomposes simultaneous encoding back into sequential traversal.\n\nInstead, each agent enters through a different door but carries ALL three:\n\n- **Feynman** enters through Door 3 (Ground · Execution · Self) — example-first, surfaces why it works\n- **Sagan** enters through Door 1 (Principle · Abstraction · Universal) — wonder-first, grounds in the tangible\n- **Tufte** enters through Door 2 (Concretions · Planning · Constituency) — who needs to see this, what makes it concrete for them\n- **Socrates** is meta — forces traversal across all doors and checks for dimensional shift\n\nThe Tufte reframe was the most significant: from \"pattern/visual structure\" to \"constituency/concretion.\" This changes the agent's first question from \"what's the right diagram type?\" to \"who needs to see this?\"\n\n## Why \"Modal Lock\" Is the Key Anti-Pattern\n\nModal lock is Claude's specific failure mode: defaulting to Door 1 (clean taxonomies, headers, structure) and amplifying when it doesn't land.\n\nWith the facet-set model, the diagnosis is more precise:\n- What's over-represented: Abstraction | Universal\n- What's missing: Constituency — the question \"who is standing at this door?\"\n- What looks like a fix but isn't: generic examples (Door 1 in Door 3's clothes)\n\n## The Missing Ground\n\nProfessional communication is almost entirely Door 1 + Door 2: docs, diagrams, logic, demos, energy. Door 3 — weight, inevitability, ground — is nearly absent from professional contexts.\n\nThe closest analog: showing the thing already working. Not a prototype. The thing itself. This is an open question in the framework — ground-level transmission may require a fundamentally different instrument than the deck or the document.\n\n## Research Base\n\nKey findings informing the design:\n\n| Finding | Source | Design Implication |\n|---------|--------|-------------------|\n| Coherence principle d=0.86 | Mayer, 23/23 tests | Cut extraneous material ruthlessly |\n| Expertise reversal d=0.505/-0.428 | Tetzlaff 2025, n=5,924 | Detect expertise, adapt guidance level |\n| WHY framing 31.5% -> 97.3% | Prompting Inversion, arXiv | Route and explain why, don't prescribe how |\n| CoVe +23% accuracy | Dhuliawala et al. 2024 | Independent verification prevents hallucination |\n| Feynman Bot 1.8x learning | Demszky et al. 2025 | Example-first teaching works |\n| Contrastive explanations | Miller 2019 | \"Why X, not Y?\" is more effective than \"Why X?\" |\n\n## Sources\n\n- Bastani et al. (2025). Generative AI without guardrails can harm learning. PNAS.\n- Dhuliawala et al. (2024). Chain-of-Verification Reduces Hallucination. ACL.\n- Miller, T. (2019). Explanation in Artificial Intelligence: Insights from the Social Sciences. AI Journal.\n- Tetzlaff et al. (2025). Expertise Reversal Effect meta-analysis. n=5,924.\n- arXiv:2510.22251. Prompting Inversion for frontier models.\n- Mayer, R. (2009). Multimedia Learning. Cambridge University Press.\n- Nielsen Norman Group. F-pattern, scanning, information architecture research.\n- \"The Three Doors: A Framework for Resonant Transmission\" — origin essay for the facet-set model.\n",{"slug":32,"title":33,"content":34},"sources","Sources and Bibliography","# Sources and Bibliography\n\nResearch informing the craft-explanations plugin design.\n\n## Pedagogy and Learning Science\n\n- Bastani, H., Bastani, O., Sungu, A., Ge, H., Kabakcı, O., & Mariman, R. (2025). Generative AI without guardrails can harm learning. *PNAS*.\n  - GPT Tutor (hints only): no harm. GPT Base (direct answers): 17% harm.\n\n- Tetzlaff, L. et al. (2025). Expertise Reversal Effect: A meta-analysis. n=5,924.\n  - High guidance helps novices (d=0.505), harms experts (d=-0.428).\n\n- Demszky, D. et al. (2025). Feynman Bot: Learning gains from AI tutoring. Stanford.\n  - 1.8x learning gains from example-first AI tutoring.\n\n- Mayer, R. (2009). *Multimedia Learning*. Cambridge University Press.\n  - Coherence principle: d=0.86 across 23/23 tests. Extraneous material harms learning.\n\n- Sweller, J. (1988). Cognitive load during problem solving. *Cognitive Science*.\n  - Three types: intrinsic, extraneous, germane. Minimize extraneous, protect germane.\n\n## Explanation Science\n\n- Miller, T. (2019). Explanation in Artificial Intelligence: Insights from the Social Sciences. *Artificial Intelligence*, 267, 1-38.\n  - Explanations are contrastive (\"Why X, not Y?\"), social, and selective.\n\n- Lombrozo, T. (2012). Explanation and abductive inference. *Oxford Handbook of Thinking and Reasoning*.\n  - Explanatory preferences shape learning and generalization.\n\n## AI and Prompting\n\n- arXiv:2510.22251. Prompting Inversion for frontier models.\n  - Explicit procedural constraints hurt frontier models. Route, don't teach. WHY framing: 31.5% to 97.3%.\n\n- Dhuliawala, S. et al. (2024). Chain-of-Verification Reduces Hallucination in Large Language Models. *ACL*.\n  - Independent verification achieves 50-70% hallucination reduction. +23% accuracy.\n\n## Cognitive Science\n\n- Lee, J. et al. (2025). The Impact of Generative AI on Critical Thinking. *CHI*.\n  - AI confidence negatively predicts critical thinking (beta = -0.69).\n\n- Kosmyna, N. et al. (2025). Your Brain on ChatGPT: Cognitive Debt. MIT Media Lab.\n  - Neural connectivity \"systematically scaled down\" with AI use (EEG study).\n\n## Reading and Information Design\n\n- Nielsen, J. (2006). F-Shaped Pattern For Reading Web Content. Nielsen Norman Group.\n  - 232 users eye-tracked. First paragraphs get most attention. Headers as signposts.\n\n- Pernice, K. (2017). F-Shaped Pattern: Misunderstood, But Still Relevant. NN/g.\n\n- Tufte, E. (1983). *The Visual Display of Quantitative Information*. Graphics Press.\n  - Data-ink ratio. Every visual element should carry information.\n\n## Information Architecture\n\n- Rosenfeld, L., Morville, P., & Arango, J. (2015). *Information Architecture: For the Web and Beyond* (4th ed.). O'Reilly.\n\n- Procida, D. (2017). Diataxis: A systematic framework for technical documentation.\n  - Tutorial / How-to / Explanation / Reference. Don't mix types.\n\n## AI Writing\n\n- Wikipedia: Signs of AI Writing.\n  - Vocabulary tells: delve, leverage, robust. Structural tells: uniform paragraphs, rule-of-three.\n\n- Shankar, S. (2025). Writing in the Age of LLMs.\n  - Stylometric analysis shows LLM text clusters tightly vs human variation.\n\n- arXiv:2509.19163. Measuring AI \"Slop\" in Text.\n\n## Philosophy\n\n- \"The Three Doors: A Framework for Resonant Transmission.\"\n  - Origin essay for the facet-set model (Principle|Abstraction|Universal → Concretions|Planning|Constituency → Ground|Execution|Self).\n  - Key concepts: directional modal lock, dimensional shift, wider-not-louder, instrumental boundaries, the missing ground.\n\n- Marr, D. (1982). *Vision*. Computational, algorithmic, implementational levels.\n  - Parallel structure: principle (computational), pattern (algorithmic), practice (implementational).\n",[],[],2],"uses":{"params":["slug"]}}]}
