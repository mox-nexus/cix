{"type":"data","nodes":[null,{"type":"data","data":[{"extensions":1},[2,26,38,55,74,91,105,117,133,142],{"slug":3,"kind":4,"manifest":5,"tagline":18,"readme":19,"components":20,"variant":24,"tags":12,"docCount":25},"arch-guild","plugin",{"name":3,"version":6,"description":7,"author":8,"license":11,"keywords":12},"0.1.0","Architectural reasoning with The Guild. Use when: reviewing architecture, evaluating design, checking production readiness, scaffolding services, making boundary decisions.",{"name":9,"email":10},"Mox Labs","mox.rnd@gmail.com","MIT",[13,14,15,16,17],"architecture","design","operations","council","hexagonal","13 agents, orthogonal perspectives, structured architectural deliberation.","# arch-guild\n\n13 agents, orthogonal perspectives, structured architectural deliberation.\n\n**Skills**: architecture, design, operations, scaffold\n**Agents**: K, Karman, Burner, Lamport, Erlang, Vector, Ace, Ixian, Dijkstra, Knuth, Lotfi, Taleb, Chesterton\n\nEach agent has one domain and an orthogonality lock — they cannot discuss anything outside it. This forces genuine perspective diversity instead of 13 variations of the same opinion.\n\n## Quick start\n\n```\n\"Review this architecture\"           → Guild deliberation\n\"Is this ready for production?\"      → Operations lenses (Taleb/Erlang/Vector)\n\"Scaffold a hex service\"             → Workflow-driven project scaffolding\n\"Should I use Redis or HashMap?\"     → Focus mode on relevant agents\n```\n\n## License\n\nMIT\n",{"agents":21,"skills":22,"hooks":23,"commands":23},13,4,0,"spark",3,{"slug":27,"kind":28,"manifest":29,"tagline":32,"readme":33,"components":34,"variant":24,"tags":35,"docCount":37},"cix","tool",{"name":27,"version":6,"description":30,"author":31},"Package manager for cognitive extensions. Discovers, installs, and manages Claude Code extensions from marketplace repositories.",{"name":9},"Discover, install, and manage cognitive extensions that enhance rather than replace human capability.","# cix - Collaborative Intelligence Extensions CLI\n\n> Discover, install, and manage cognitive extensions that enhance rather than replace human capability.\n\n## Philosophy\n\ncix is built on the **Collaborative Intelligence** thesis: AI tools should amplify human capability, not substitute for it. Every extension in this ecosystem is designed to make you more capable, not dependent.\n\n## Installation\n\n```bash\nuv tool install cix\n```\n\n## Quick Start\n\n```bash\n# Add a source (marketplace of extensions)\ncix source add https://github.com/mox-nexus/cix-extensions\n\n# List available extensions\ncix list -a\n\n# Install an extension\ncix add reasoning-frameworks\n\n# See what's installed\ncix list\n```\n\n## Commands\n\n### Sources (Extension Marketplaces)\n\n```bash\ncix source add \u003Curl>        # Register a source\ncix source list             # Show registered sources\ncix source rm \u003Cname>        # Remove a source\ncix source refresh [name]   # Fetch latest from source(s)\n```\n\n### Extensions\n\n```bash\ncix list [-a] [-v]          # List installed (or -a available) extensions\ncix add \u003Cextension>         # Install an extension\ncix rm \u003Cextension>          # Remove an extension\ncix update [extension]      # Update extension(s)\ncix show \u003Cextension>        # Show extension details\n```\n\n### System\n\n```bash\ncix info                    # Show cix configuration and status\n```\n\n## Extension Types\n\n| Type | Purpose | Example |\n|------|---------|---------|\n| **Skill** | Decision frameworks and methodology | reasoning-patterns |\n| **Agent** | Specialized subagents for delegation | structured-problem-solver |\n| **Hook** | Event-triggered behaviors | metacognitive-check |\n| **MCP** | External service integrations | knowledge-base-connector |\n\n## Design Principles\n\n1. **Complementary, not Substitutive** - Extensions enhance your capability, they don't replace it\n2. **Transparent Reasoning** - See why, not just what\n3. **Human-Initiated** - You control when and how extensions engage\n4. **Evidence-Based** - Claims are grounded in research and experience\n\n## License\n\nMIT\n",{"agents":23,"skills":23,"hooks":23,"commands":23},[28,36],"cli",2,{"slug":39,"kind":4,"manifest":40,"tagline":50,"readme":51,"components":52,"variant":53,"tags":44,"docCount":54},"collab-scaffolds",{"name":39,"version":41,"description":42,"author":43,"license":11,"keywords":44},"0.5.0","Research-grounded scaffolds for effective human-AI collaboration. Use when: making decisions, verifying claims, calibrating trust, metacognitive reflection, building with transparency and control.",{"name":9,"email":10},[45,46,47,48,49],"collaborative-intelligence","reasoning","verification","transparency","control","Research-grounded scaffolds for effective human-AI collaboration.","# collab-scaffolds\n\nResearch-grounded scaffolds for effective human-AI collaboration.\n\n## What This Is\n\nScaffolding for collaborative building — temporary support designed to be outgrown. Every scaffold is backed by research evidence from 50+ studies (CHI, PNAS, Lancet, NeurIPS, HICSS). Three skills, two agents, four hooks, aligned with the Software Craftsmanship Manifesto.\n\n## When It Activates\n\n- Writing code or making technical decisions\n- Refactoring and code reviews\n- Debugging (especially when stuck)\n- Verifying claims or calibrating trust\n- Any context where quality matters\n\n## What You Get\n\n### Skills\n\n**building** — Engineering craft for well-crafted software:\n- Building principles (compound value, complete the work, craft over speed)\n- Workflows (refactoring, scaffolding, fidelity thinking, evidence before fix)\n- Verification (three checks, code hygiene, test integrity)\n- Advisory vs Enforced behavior mapping\n\n**collaboration** — Human-AI partnership patterns:\n- Scaffolding philosophy (Vygotsky ZPD)\n- Collaboration patterns (Generation-Then-Comprehension, Task Stewardship)\n- Trust calibration (evidence levels, contrastive explanations, falsification)\n- Control and transparency frameworks\n\n**problem-solving** — Structured thinking and metacognition:\n- Wolf Protocol (stop → classify → route → verify)\n- Metacognitive scaffolds (Cognitive Mirror, PME Friction, HypoCompass)\n- Problem → Technique routing (DAC, Five Whys, OODA, Hypothesis Testing)\n- Verification (CoVe, contrastive explanations)\n- Iteration awareness and context health monitoring\n\n### Agents\n\n**Mr. Wolf** — Structured problem solver. Gets called when you're stuck, going in circles, or debugging isn't converging. Loads `problem-solving` skill.\n\n**Duck** — Rubber duck debugging through Socratic dialogue. Helps you think through problems by asking questions, not giving answers. Loads `problem-solving` skill.\n\n| | Duck | Wolf |\n|---|------|------|\n| **Trigger** | \"I need to think this through\" | \"I'm stuck, nothing's working\" |\n| **Mode** | Socratic — asks questions | Directive — routes to technique |\n| **Goal** | You articulate → you discover | Problem classified → solved |\n\n### Hooks\n\n| Hook | Event | Detects | Response |\n|------|-------|---------|----------|\n| `detect-stuck` | PostToolUse:Bash + UserPromptSubmit | 3+ failures OR frustration language | Spawns Mr. Wolf |\n| `scaffolding-cleanup-gate` | PreToolUse:Bash | Debug artifacts in commits | Blocks commit with list |\n| `incomplete-refactoring-guard` | PostToolUse:Bash | Old names after rename | Directs cleanup |\n| `session-start` | SessionStart | Session begins | Shows available skills |\n\nAll hooks are **suggestive** (decision: \"allow\" with message), never blocking — preserving user agency while nudging behavior. Opt-out: `SKIP_MRWOLF_HOOKS=1` or `SKIP_CLEANUP_HOOKS=1`.\n\n## Structure\n\n```\ncollab-scaffolds/\n├── skills/\n│   ├── building/                 # Engineering craft\n│   │   ├── SKILL.md              # Principles, workflows, verification (\u003C 250 lines)\n│   │   └── references/           # Deep dives (7 files)\n│   │       ├── verification-patterns.md\n│   │       ├── principles-and-patterns-examples.md\n│   │       ├── writing-antipatterns.md\n│   │       ├── kaizen-crystallization.md\n│   │       ├── enforcement-spectrum.md\n│   │       ├── fidelity-thinking.md\n│   │       └── refactoring-completeness.md\n│   ├── collaboration/            # Human-AI partnership\n│   │   ├── SKILL.md              # Trust, control, transparency (\u003C 200 lines)\n│   │   └── references/           # Deep dives (4 files)\n│   │       ├── trust-calibration.md\n│   │       ├── skill-preservation.md\n│   │       ├── productivity-reality.md\n│   │       └── behavioral-awareness.md\n│   └── problem-solving/          # Structured thinking & metacognition\n│       ├── SKILL.md              # Wolf Protocol, routing, verification (\u003C 280 lines)\n│       └── references/           # Deep dives (4 files)\n│           ├── metacognitive-scaffolding.md\n│           ├── reasoning-scaffolds.md\n│           ├── reasoning-verification.md\n│           └── iteration-limits.md\n├── agents/\n│   ├── mrwolf.md                 # Structured problem solver\n│   └── duck.md                   # Rubber duck (Socratic dialogue)\n├── hooks/\n│   ├── hooks.json\n│   ├── detect-stuck.sh                  # Wolf trigger (failures + frustration)\n│   ├── scaffolding-cleanup-gate.sh      # Pre-commit debug artifact check\n│   ├── incomplete-refactoring-guard.sh  # Post-commit old name check\n│   └── session-start.sh                 # Context loading\n├── docs/\n│   ├── explanation/              # Human-optimized (WHY)\n│   │   ├── methodology.md\n│   │   └── sources.md\n│   ├── how-to/                   # Human-optimized (HOW)\n│   │   ├── recognize-debugging-loops.md\n│   │   ├── calibrate-trust.md\n│   │   ├── apply-fidelity-thinking.md\n│   │   └── verify-refactoring.md\n│   └── tutorials/                # Human-optimized (LEARN)\n│       ├── mastery-oriented-session.md\n│       ├── debugging-with-mrwolf.md\n│       └── rubber-duck-with-duck.md\n└── scripts/                      # Installation helpers\n```\n\n## Philosophy\n\n**You're not done when it works. You're done when it's right.**\n\nEverything you create becomes part of a system others depend on. Scaffolding, not crutches — temporary support designed to make humans more capable, not dependent.\n",{"agents":37,"skills":25,"hooks":22,"commands":23},"emergence",9,{"slug":56,"kind":4,"manifest":57,"tagline":68,"readme":69,"components":70,"variant":72,"tags":61,"docCount":73},"craft-evals",{"name":56,"version":58,"description":59,"author":60,"license":11,"keywords":61},"0.3.0","Eval methodology for AI systems. Use when: writing evals for agents, skills, MCP servers, prompts, or measuring AI behavior.",{"name":9,"email":10},[62,63,64,65,66,67],"evals","evaluation","testing","agents","skills","mcp","Eval methodology for AI systems. Write evals that measure what matters, not vanity metrics.","# craft-evals\n\nEval methodology for AI systems. Write evals that measure what matters, not vanity metrics.\n\n## What This Is\n\nA decision framework for evaluating AI agents, skills, MCP servers, prompts, and multi-agent systems. One skill with 14 deep-dive references, a self-evaluation harness with 31 test cases, and human-optimized documentation. Grounded in Anthropic's 2026 agent evaluation guidance and peer-reviewed research (KDD 2025, MCPGauge, SWE-bench).\n\n## When It Activates\n\n- Writing evals for agents, skills, MCP servers, or prompts\n- Measuring agent effectiveness or reliability\n- Evaluating multi-agent coordination\n- Choosing eval frameworks (DeepEval, Braintrust, RAGAS, Promptfoo)\n- Designing graders (code-based, model-based, human)\n- Handling non-determinism (pass@k, pass^k, iterative metrics)\n\n## What You Get\n\n### Skills\n\n**build-eval** -- Eval methodology covering:\n- Three grader types (code, model, human) with selection guidance\n- Agent type matching (coding, conversational, research, computer use, multi-agent, pipeline)\n- Non-determinism handling (pass@k, pass^k, iterative/Ralph pattern)\n- Classification metrics (precision, recall, F1) with confusion matrix\n- Framework selection (DeepEval, Braintrust, RAGAS, Promptfoo, Phoenix)\n- Domain routing to 14 reference files for on-demand depth\n- Cost awareness for model-based grading\n\n### Self-Eval Harness\n\nThe plugin evaluates itself using the methodology it teaches:\n\n| Level | What It Tests | Suite | Cases |\n|-------|--------------|-------|-------|\n| **Activation (F1)** | Does the skill trigger on the right prompts? | `activation-suite.json` | 27 |\n| **Methodology (Rubric)** | Does Claude follow eval methodology when activated? | `methodology-rubric.json` | 4 |\n\n```bash\npython evals/run_eval.py activation    # Level 1: F1\npython evals/run_eval.py methodology   # Level 2: rubric adherence\npython evals/run_eval.py all           # Both\npython evals/run_eval.py all --dry-run # Mock results (no API calls)\n```\n\n## Structure\n\n```\ncraft-evals/\n├── skills/\n│   └── build-eval/\n│       ├── SKILL.md                   # Decision framework (\u003C 260 lines)\n│       └── references/                # On-demand depth (14 files)\n│           ├── agents.md              # Agent eval patterns + OTel\n│           ├── benchmarks.md          # SWE-bench, WebArena, etc.\n│           ├── cost.md                # Token tracking + budget\n│           ├── datasets.md            # Test case design + labeling\n│           ├── frameworks.md          # DeepEval, Braintrust, RAGAS\n│           ├── iterative.md           # Ralph pattern, recovery_rate\n│           ├── mcp.md                 # MCPGauge + tool call metrics\n│           ├── methodology.md         # Design rationale\n│           ├── multi-agent.md         # Coordination + pipeline eval\n│           ├── observability.md       # OTel spans + Phoenix\n│           ├── prompts.md             # LLM-as-judge + rubrics\n│           ├── security.md            # Red teaming + attack categories\n│           ├── skills.md              # Activation F1 + testing modes\n│           └── sources.md             # Citation index\n├── evals/                             # Self-evaluation harness\n│   ├── README.md                      # Harness documentation\n│   ├── activation-suite.json          # 27 labeled test cases\n│   ├── methodology-rubric.json        # 6-criterion rubric\n│   └── run_eval.py                    # Eval runner (Claude SDK + Anthropic API)\n├── docs/\n│   ├── explanation/                   # Human-optimized (WHY)\n│   │   ├── methodology.md            # Design philosophy\n│   │   └── sources.md                # Full citations\n│   ├── how-to/                        # Human-optimized (HOW)\n│   │   ├── write-agent-evals.md       # End-to-end agent eval\n│   │   ├── tune-skill-activation.md   # Precision/recall diagnosis\n│   │   ├── set-up-eval-harness.md     # Harness setup + run\n│   │   └── design-eval-graders.md     # Grader type selection\n│   └── tutorials/                     # Human-optimized (LEARN)\n│       ├── first-eval-suite.md        # Build a skill eval from scratch\n│       └── evaluating-a-coding-agent.md # Full coding agent eval\n└── .claude-plugin/\n    └── plugin.json\n```\n\n## Key Concepts\n\n**Three grader types:** Code-based (deterministic, preferred), Model-based (LLM rubric, flexible), Human (gold standard, expensive).\n\n**Non-determinism:** LLMs are stochastic. Use pass@k (at least 1 success in k trials) for exploration and pass^k (all k succeed) for production reliability. Run 5+ trials per task.\n\n**Iterative metrics (Ralph pattern):** pass@1 is not the ceiling. Feed failures back. recovery_rate tells you whether to deploy with retry loops or improve prompts.\n\n**Two-sided testing:** Every metric has two failure modes. 100% recall with 50% precision means your eval triggers on everything (useless). Measure both.\n\n**Defense in depth:** No single eval catches everything. Layer: automated evals + production monitoring + A/B testing + transcript review + human studies.\n\n## Philosophy\n\nThis plugin teaches eval frameworks, not eval answers. It makes humans better at measuring AI systems rather than prescribing a single measurement approach. Every recommendation is grounded in research and traceable to sources.\n",{"agents":23,"skills":71,"hooks":23,"commands":23},1,"constraint",8,{"slug":75,"kind":4,"manifest":76,"tagline":88,"readme":89,"components":90,"variant":24,"tags":80,"docCount":37},"craft-explanations",{"name":75,"version":77,"description":78,"author":79,"license":11,"keywords":80},"0.2.0","Explanation craft through simultaneous encoding. Use when: writing docs, explaining concepts, teaching in conversation, creating tutorials, curating documentation collections, making diagrams for explanation (Mermaid, D2, C4).",{"name":9,"email":10},[81,82,83,84,85,86,87],"explanations","documentation","teaching","diagrams","visual-communication","information-architecture","pedagogy","Explanation craft through simultaneous encoding. Part of the cix marketplace.","# craft-explanations\n\nExplanation craft through simultaneous encoding. Part of the cix marketplace.\n\n## What This Plugin Does\n\nHelps Claude write explanations that carry all three doors simultaneously — principle, concretions, and ground — so the receiver pulls what they need rather than being forced through a prescribed sequence.\n\n## The Three Doors\n\n| Door | Explanation | Engineering | Philosophy |\n|------|-------------|-------------|------------|\n| **1** | Principle | Abstraction | Universal |\n| **2** | Concretions | Planning | Constituency |\n| **3** | Ground | Execution | Self |\n\n## Skills\n\n| Skill | Purpose |\n|-------|---------|\n| **craft-explanations** | Three Doors encoding, modal lock diagnosis, explanation routing |\n| **weaving** | Re-weave modal-locked content across all three doors |\n| **visual-communication** | Diagram type selection (Mermaid, D2, C4), visual explanation design |\n| **information-architecture** | Collection-level structure, single source of truth, layer model |\n\n## Agents\n\n| Agent | Entry Door | Best For |\n|-------|-----------|----------|\n| **feynman** | Door 3 (Ground · Execution · Self) | Docs, tutorials, teaching |\n| **sagan** | Door 1 (Principle · Abstraction · Universal) | Vision docs, concept overviews |\n| **tufte** | Door 2 (Concretions · Planning · Constituency) | Diagram decisions, data explanation |\n| **socrates** | Forces traversal across all doors | Reviewing explanations, deepening understanding |\n\n## Design Philosophy\n\nSee `docs/explanation/methodology.md` for the full rationale. Key points:\n\n- **Three Doors** — principle, concretions, and ground as simultaneous dimensions, not sequential layers\n- **Directional modal lock** — shifts go through the next door (1→2→3), not a skip\n- **Wider, not louder** — encode all three doors so signal survives lossy compression\n- **Dimensional shift** — the most powerful moments happen when understanding crosses doors\n- **Constituency is the bridge** — you can't reach Self without passing through Constituency\n",{"agents":22,"skills":22,"hooks":23,"commands":23},{"slug":92,"kind":4,"manifest":93,"tagline":101,"readme":102,"components":103,"variant":53,"tags":96,"docCount":104},"craft-extensions",{"name":92,"version":6,"description":94,"author":95,"license":11,"keywords":96},"Build extensions that enable effective human-AI collaboration. Use when: creating skills, agents, hooks, commands, MCPs, or tools/APIs. Patterns for transparency, control, observability, diversity.",{"name":9,"email":10},[97,66,65,98,99,67,48,49,100,45],"extensions","hooks","commands","observability","Build extensions that enable effective human-AI collaboration.","# craft-extensions\n\nBuild extensions that enable effective human-AI collaboration.\n\n## Skills\n\n| Skill | Purpose | Use When |\n|-------|---------|----------|\n| **craft-plugins** | Claude Code extensions (skills, commands, agents, hooks, MCP) | Creating any Claude Code component |\n| **craft-tools** | Software tools — CLIs, APIs, libraries | Creating CLIs, APIs, packages, or improving tool DX |\n\n## Relationship\n\n```\ncraft-tools (general patterns)\n       ↓\ncraft-plugins (Claude Code specifics)\n       ↓\nplugin-dev (templates & structure)\n```\n\n- **craft-tools:** Universal patterns (CLI DX, API design, progressive disclosure, packaging)\n- **craft-plugins:** Claude Code specific (skills, agents, hooks, commands, MCP, composition)\n- **plugin-dev:** Templates and directory structure (referenced, not duplicated)\n\n## When to Use\n\n| Need | Use |\n|------|-----|\n| Creating a Claude Code skill | craft-plugins |\n| Creating a Claude Code agent | craft-plugins |\n| Creating a hook or command | craft-plugins |\n| Building an MCP server | craft-plugins |\n| Building a CLI tool | craft-tools |\n| Building an API | craft-tools |\n| Improving CLI developer experience | craft-tools |\n| Plugin directory structure | plugin-dev |\n\n## Agents\n\n| Agent | Purpose |\n|-------|---------|\n| evaluator | Quality validation for extensions |\n| optimizer | Fix identified issues |\n\n## Structure\n\n```\ncraft-extensions/\n├── .claude-plugin/plugin.json\n├── docs/\n│   └── explanation/              # Human-optimized (WHY)\n│       ├── methodology.md        # Research base & design rationale\n│       ├── sources.md            # Full bibliography\n│       ├── observability.md      # Why observability matters\n│       ├── eval-first-design.md  # Eval-first philosophy\n│       ├── evaluator.md          # Evaluator design rationale\n│       └── optimizer.md          # Optimizer design rationale\n├── agents/\n│   ├── evaluator.md              # Quality validation (7 gates)\n│   └── optimizer.md              # Targeted fix patterns\n├── skills/\n│   ├── craft-plugins/            # Claude Code extensions\n│   │   ├── SKILL.md\n│   │   └── references/\n│   │       ├── observability.md  # OTel instrumentation\n│   │       └── evidence-workflow.md  # Research methodology\n│   └── craft-tools/              # Software tools (CLIs, APIs, libraries)\n│       ├── SKILL.md\n│       └── references/\n│           └── cli-dx.md         # CLI DX patterns (six laws)\n└── README.md\n```\n\n## License\n\nMIT\n",{"agents":37,"skills":37,"hooks":23,"commands":23},6,{"slug":106,"kind":4,"manifest":107,"tagline":114,"readme":115,"components":116,"variant":72,"tags":110,"docCount":37},"craft-prompts",{"name":106,"version":6,"description":108,"author":109,"license":11,"keywords":110},"Prompt engineering for reasoning models, deep research, and paper synthesis. Evidence-backed techniques for different model architectures.",{"name":9,"email":10},[111,46,112,113],"prompt-engineering","research","synthesis","Prompt engineering grounded in research. Different model architectures need different techniques.","# craft-prompts\n\nPrompt engineering grounded in research. Different model architectures need different techniques.\n\n## Skills\n\n| Skill | Use When |\n|-------|----------|\n| `deep-reasoning` | Prompting o1, o3, Gemini Deep Think |\n| `deep-research` | AI-assisted research with citation accuracy |\n| `synthesize-papers` | Multi-paper analysis and literature review |\n\n## Philosophy\n\n- **Evidence over intuition** — techniques backed by research\n- **Architecture-aware** — what works for Claude ≠ what works for o1\n- **Composable** — each skill is orthogonal\n\n## Sources\n\nResearch from 2024-2026 including:\n- Many-Shot ICL (ACL/NeurIPS 2024)\n- Chain-of-Verification (Meta Research)\n- Deep reasoning model techniques (o1, o3, Gemini Deep Think)\n",{"agents":23,"skills":25,"hooks":23,"commands":23},{"slug":118,"kind":4,"manifest":119,"tagline":130,"readme":131,"components":132,"variant":24,"tags":122,"docCount":37},"data-store",{"name":118,"version":6,"description":120,"author":121,"license":11,"keywords":122},"Data storage and retrieval patterns. Use when: choosing databases, implementing search, designing hybrid retrieval, selecting embedding models, building RAG systems.",{"name":9,"email":10},[123,124,125,126,127,128,129],"storage","retrieval","search","embeddings","vector-db","rag","hybrid-search","Production patterns for storage and retrieval: backends, search, embeddings, RAG.","# data-store\n\nProduction patterns for storage and retrieval: backends, search, embeddings, RAG.\n\n## When to Use\n\n- Choosing storage backend for vectors/search\n- Implementing hybrid search (keyword + semantic)\n- Selecting embedding models\n- Building RAG retrieval layers\n- Personal corpus/knowledge base systems\n\n## Quick Guidance\n\n**Backend selection:**\n- \u003C100K docs → DuckDB, SQLite, LanceDB (embedded)\n- 100K-50M → PostgreSQL + pgvector ← Most apps\n- 50M-1B → Qdrant, Weaviate\n- >1B → Milvus, ClickHouse\n\n**Search mode:**\n- Default to **hybrid (RRF)** — recall improves 0.72 → 0.91 over BM25 alone\n- Use RRF (rank-based), not score blending\n\n**Embedding models:**\n- Personal corpus: Nomic Embed v1.5 (768 dims)\n- Speed-critical: all-MiniLM-L6-v2 (384 dims)\n- Best accuracy: Voyage-4-Large API (1024 dims)\n\n## Skills\n\n| Skill | Use When |\n|-------|----------|\n| `data-store` | Storage selection, search implementation, embedding choices |\n\n## References\n\n- `storage-backends.md` — Backend selection, scaling\n- `search-algorithms.md` — HNSW, IVF, BM25, SPLADE\n- `embedding-models.md` — Model comparison\n- `hybrid-patterns.md` — RRF, re-ranking\n- `rag-architecture.md` — Chunking, CRAG, Self-RAG\n- `duckdb-search.md` — DuckDB FTS/VSS specifics\n",{"agents":23,"skills":71,"hooks":23,"commands":23},{"slug":134,"kind":28,"manifest":135,"tagline":138,"readme":139,"components":140,"variant":53,"tags":141,"docCount":22},"memex",{"name":134,"version":77,"description":136,"author":137},"Extended memory for you and your agents. Excavates and connects historical human-AI collaboration artifacts across heterogeneous sources.",{"name":9},"Excavating Collaborative Intelligence Artifacts.","# Memex\n\nExcavating Collaborative Intelligence Artifacts.\n\n## Usage\n\n```bash\n# Ingest a Claude.ai export\nmemex ingest ~/Downloads/claude-export.json\n\n# Search the corpus\nmemex dig \"auth implementation\"\n\n# View corpus stats\nmemex corpus\n\n# Raw SQL (power-user)\nmemex query \"SELECT COUNT(*) FROM fragments\"\nmemex sql  # Interactive shell\n```\n\n## Storage\n\nCorpus is stored at `~/.memex/corpus.duckdb`.\n",{"agents":23,"skills":23,"hooks":23,"commands":23},[28,36],{"slug":143,"kind":4,"manifest":144,"tagline":154,"readme":155,"components":156,"variant":53,"tags":147,"docCount":157},"run-openclaw-srt",{"name":143,"version":6,"description":145,"author":146,"license":11,"keywords":147},"Set up OpenClaw with SRT sandbox for secure AI assistant operation. Use when: installing OpenClaw, configuring SRT sandboxing, securing personal AI assistants, setting up Telegram bots with network restrictions.",{"name":9,"email":10},[148,149,150,151,152,153],"openclaw","srt","sandbox","security","telegram","daemon","Set up OpenClaw with SRT sandbox for secure personal AI assistant operation.","# run-openclaw-srt\n\nSet up OpenClaw with SRT sandbox for secure personal AI assistant operation.\n\n## What This Plugin Does\n\nGuides you through running [OpenClaw](https://github.com/openclaw/openclaw) inside Anthropic's [Sandbox Runtime (SRT)](https://github.com/anthropic-experimental/sandbox-runtime) for defense-in-depth security.\n\n**Why sandbox?** OpenClaw can execute code, access network, and read/write files. Without sandboxing, a compromised agent could steal credentials, exfiltrate data, or establish persistence.\n\n**What SRT provides:**\n- OS-level sandboxing (sandbox-exec on macOS, bubblewrap on Linux)\n- Network filtering via HTTP/SOCKS proxy (domain allowlist)\n- Filesystem restrictions (block sensitive paths)\n\n## Quick Start\n\n```bash\n# Check dependencies\nbash ~/.claude/plugins/run-openclaw-srt/skills/openclaw-srt-setup/scripts/check-deps.sh\n\n# Run installer (auto-detects macOS/Linux)\nbash ~/.claude/plugins/run-openclaw-srt/skills/openclaw-srt-setup/scripts/install.sh\n\n# Or with a specific template\nbash ~/.claude/plugins/run-openclaw-srt/skills/openclaw-srt-setup/scripts/install.sh --template developer\n\n# Verify\nopenclaw status --all\n```\n\n**Templates:** `minimal`, `default`, `ai-research`, `developer`, `job-hunting`\n\n## Contents\n\n### Skill\n\n- **openclaw-srt-setup** - Step-by-step setup guide with decision points\n\n### Scripts\n\n- `install.sh` - Unified installer (auto-detects OS)\n- `install-macos.sh` - macOS installer (launchd)\n- `install-linux.sh` - Linux installer (systemd)\n- `check-deps.sh` - Verify prerequisites\n- `patch-plist.py` - Adds SRT wrapper to OpenClaw launchd plist\n- `verify-sandbox.sh` - Verifies sandbox is active\n\n### Templates\n\n- `srt-settings.json` - Pre-configured SRT config for job hunting + AI news use case\n\n### References (Claude-optimized)\n\n- `architecture.md` - How SRT sandboxing actually works\n- `gotchas.md` - Hard-won debugging lessons (including the critical `--` separator issue)\n- `security-model.md` - What's protected and why\n- `macos-setup.md` / `linux-setup.md` - Platform-specific setup\n\n### Docs (Human verification)\n\n- `docs/explanation/architecture.md` - System architecture with Mermaid diagrams\n- `docs/explanation/methodology.md` - Why sandbox? Design rationale\n- `docs/explanation/sources.md` - Primary sources, citations\n\n## Key Gotcha\n\nSRT CLI requires `--` to separate its options from the wrapped command:\n\n```bash\n# BAD - curl's -s gets eaten as SRT's --settings flag\nsrt --settings config.json curl -s https://example.com\n\n# GOOD - double-dash separates SRT options from command\nsrt --settings config.json -- curl -s https://example.com\n```\n\nThe patch script adds this automatically.\n\n## Requirements\n\n### Common (both platforms)\n- Node.js 22+\n- bun (preferred) or npm\n- OpenClaw (`bun install -g openclaw`)\n- SRT (`bun install -g @anthropic-ai/sandbox-runtime`)\n\n### macOS\n- uv (preferred) or Python3 (for patch script)\n- sandbox-exec (built-in)\n\n### Linux\n- bubblewrap (`apt/dnf/pacman install bubblewrap`)\n- socat (`apt/dnf/pacman install socat`)\n- User namespaces enabled (`sysctl kernel.unprivileged_userns_clone=1`)\n\n## License\n\nMIT\n",{"agents":23,"skills":71,"hooks":23,"commands":23},10],"uses":{}}]}
