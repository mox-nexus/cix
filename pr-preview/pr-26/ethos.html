<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="./_app/immutable/assets/0.04mfEt8Y.css" rel="stylesheet">
		<link href="./_app/immutable/assets/CrossLinks.C4T6atsV.css" rel="stylesheet">
		<link href="./_app/immutable/assets/6.Z3Lwgvmw.css" rel="stylesheet">
		<link rel="modulepreload" href="./_app/immutable/entry/start.P5EgdSjT.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DOTpK9Mq.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/iyO_HpW3.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_cEvoN5f.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/D0iwhpLH.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/nnUXDhQR.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Cs0QLTHR.js">
		<link rel="modulepreload" href="./_app/immutable/entry/app.DOouVLp1.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BPYyHSBz.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/2hgU3PCP.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/C4-dLuTv.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/_Dz5Oby6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/DtLL33Bf.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/a8oTfHeT.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/CFsY3MpS.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/0.u0FGVUe6.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BwsKPAvP.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BbhyhsYm.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/Dx7ODcuM.js">
		<link rel="modulepreload" href="./_app/immutable/nodes/6.DABikbSp.js">
		<link rel="modulepreload" href="./_app/immutable/chunks/BFxfVKZg.js"><!--12qhfyh--><meta name="description" content="Extensions that enhance human capability, not replace it."/><!----><!--mrcr9q--><meta name="description" content="What we build and why, grounded in research. The evidence for collaborative intelligence."/><!----><title>Ethos — cix</title>
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><a href="#main" class="skip-link">Skip to content</a> <!--[--><nav class="site-nav svelte-qgym72" aria-label="Site navigation"><a href="./" class="nav-wordmark svelte-qgym72">cix</a> <div class="nav-links svelte-qgym72"><!--[--><a href="./ethos" class="nav-link svelte-qgym72">ethos</a><a href="./catalog" class="nav-link svelte-qgym72">catalog</a><a href="./library" class="nav-link svelte-qgym72">library</a><!--]--></div></nav><!--]--> <div class="page svelte-12qhfyh has-nav"><!--[!--><!----><main id="main" class="ethos svelte-mrcr9q"><nav class="progress-nav svelte-2xr5d6" aria-label="Section navigation"><ol class="progress-list svelte-2xr5d6"><!--[--><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6 active" aria-current="step"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">The Productivity Illusion</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">The Hollowing Problem</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">Homogenization</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">What Makes Collaboration Work</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">The Trust Paradox</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">Complementary vs Substitutive</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">Cognitive Extensions</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">Design Constraints</span></button></li><li class="progress-item svelte-2xr5d6"><button class="progress-button svelte-2xr5d6"><span class="progress-dot svelte-2xr5d6"></span> <span class="progress-label svelte-2xr5d6">The Goal</span></button></li><!--]--></ol></nav><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="illusion" id="illusion"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h1 class="svelte-mrcr9q">Something is broken.</h1> <p class="lead svelte-mrcr9q">Not the outputs — the outputs look fine. The problem is underneath.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="dueling-stats svelte-1f0kcu6"><div class="stat stat-left svelte-1f0kcu6"><span class="stat-value svelte-1f0kcu6">0%</span> <span class="stat-label svelte-1f0kcu6">perceived faster</span></div> <div class="stat-gap svelte-1f0kcu6"><span class="gap-line svelte-1f0kcu6"></span></div> <div class="stat stat-right svelte-1f0kcu6"><span class="stat-value svelte-1f0kcu6">0%</span> <span class="stat-label svelte-1f0kcu6">measured slower</span></div></div><!----> <p class="paradox-note svelte-mrcr9q">METR ran a randomized controlled trial with 16 experienced developers
				on mature codebases. AI tools made them <strong>19% slower</strong>.
				They predicted being 24% faster.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>That 43-point perception gap isn't an anomaly. It's the cost of getting
				collaboration wrong. Developers feel faster but measure slower — and the gap
				between what people believe and what is true widens with each delegation.</p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="hollowing" id="hollowing"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">The hollowing problem</h2> <p>The real cost isn't time. It's capability. Three things degrade with substitutive AI use:</p> <ol class="degradation-list svelte-mrcr9q"><li class="svelte-mrcr9q"><strong>Skill to produce</strong> — you stop practicing</li> <li class="svelte-mrcr9q"><strong>Judgment to evaluate</strong> — you can't assess what you didn't build</li> <li class="svelte-mrcr9q"><strong>Metacognition to notice the loss</strong> — you can't feel yourself getting worse</li></ol> <p>This is why the 43-point gap exists.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="research-table svelte-1c6cdgx"><table class="svelte-mrcr9q"><thead><tr><th>Finding</th><th>Source</th></tr></thead><tbody><tr><td>~20% skill degradation in AI-assisted groups vs control</td><td class="citation">Lee &amp; Bastani, 2025</td></tr><tr><td>Junior developers show greatest dependency effects</td><td class="citation">Budzyń et al., 2025</td></tr><tr><td>Metacognitive monitoring impaired after extended AI assistance</td><td class="citation">Kosmyna et al., 2024</td></tr><tr><td>Passive consumption predicts atrophy; active engagement does not</td><td class="citation">Nature Human Behaviour, 2024</td></tr></tbody></table><!----></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>This is not "humans get lazy." It's a feedback loop.
				Tool replaces thought. Human stops practicing. Human can't evaluate output.
				Human loses judgment. Dependency deepens.</p> <p>The loop is invisible from inside.</p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="homogenization" id="homogenization"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">Homogenization</h2> <p>Given the same prompt, AI-assisted work converges toward identical outputs.
				Ten developers who would have produced ten architectures now produce one.
				Diversity of human perspective erodes into monoculture.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="research-table svelte-1c6cdgx"><table class="svelte-mrcr9q"><thead><tr><th>Finding</th><th>Source</th></tr></thead><tbody><tr><td>AI-assisted solutions show significantly reduced variance across practitioners</td><td class="citation">Convergent output analysis, multiple studies</td></tr><tr><td>Competitive pressure selects for substitutive engagement patterns</td><td class="citation">Organizational behavior research</td></tr></tbody></table><!----></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>Market pressure locks this in. Teams that delegate fully ship faster this quarter.
				By the time fragility surfaces — brittle architectures, undetected failures,
				homogenized thinking — the atrophy is deep and the incentive structure
				rewards more of it.</p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="collaboration" id="collaboration"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">What makes collaboration work</h2> <p>Blaurock et al. studied what factors predict successful human-AI collaboration.
				The results split cleanly.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="research-table svelte-1c6cdgx"><table class="svelte-mrcr9q"><thead><tr><th>Factor</th><th>Effect</th></tr></thead><tbody><tr><td>Transparency of AI reasoning</td><td class="positive">Positive predictor</td></tr><tr><td>Human sense of control</td><td class="positive">Positive predictor</td></tr><tr><td>Reciprocity in interaction</td><td class="positive">Positive predictor</td></tr><tr><td>Engagement features (gamification, polish)</td><td class="negative">Negative predictor</td></tr><tr><td>AI anthropomorphization</td><td class="negative">Negative predictor</td></tr><tr><td>Ease of delegation (low friction to hand off)</td><td class="negative">Negative predictor</td></tr></tbody></table><!----></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>The features that make AI tools <em>feel</em> good — smooth UX, low friction,
				personality — predict worse outcomes. The features that make collaboration <em>work</em> — transparency, control, reciprocity — often feel like friction.</p> <p><strong>This is the design trap.</strong></p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="trust" id="trust"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">The trust paradox</h2> <p>The most counterintuitive finding. High use doesn't mean high trust.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="dueling-stats svelte-1f0kcu6"><div class="stat stat-left svelte-1f0kcu6"><span class="stat-value svelte-1f0kcu6">0%</span> <span class="stat-label svelte-1f0kcu6">use AI</span></div> <div class="stat-gap svelte-1f0kcu6"><span class="gap-line svelte-1f0kcu6"></span></div> <div class="stat stat-right svelte-1f0kcu6"><span class="stat-value svelte-1f0kcu6">0%</span> <span class="stat-label svelte-1f0kcu6">trust it</span></div></div><!----> <p class="paradox-note svelte-mrcr9q">Most developers use AI despite not trusting it. Trust dropped from 43% to 33%
				even as adoption rose.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>This isn't irrational — it's strategic. Developers have learned that AI output
				requires verification but is still worth generating.</p> <div class="trust-comparison svelte-mrcr9q"><div class="trust-group svelte-mrcr9q"><span class="trust-label svelte-mrcr9q">Seniors</span> <span class="trust-stat warning svelte-mrcr9q">Low trust</span> <span class="trust-outcome success svelte-mrcr9q">Verify effectively, ship 2.5x more</span></div> <div class="trust-group svelte-mrcr9q"><span class="trust-label svelte-mrcr9q">Juniors</span> <span class="trust-stat svelte-mrcr9q">Higher trust</span> <span class="trust-outcome warning svelte-mrcr9q">Lack skill base to know what to check</span></div></div><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="complementary" id="complementary"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">Complementary vs substitutive</h2> <p>The same tool can operate in any of these modes depending on how it's designed:</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="research-table svelte-1c6cdgx"><table class="svelte-mrcr9q"><thead><tr><th>Mode</th><th>Description</th><th>Outcome</th></tr></thead><tbody><tr><td><strong>Complementary</strong></td><td>AI fills genuine gaps in human capability</td><td class="positive">Human grows, system strengthens</td></tr><tr><td><strong>Constitutive</strong></td><td>AI and human form a new joint capability neither had alone</td><td class="positive">Novel emergence, both essential</td></tr><tr><td><strong>Substitutive</strong></td><td>AI replaces human thought where human is capable</td><td class="negative">Human atrophies, system degrades</td></tr></tbody></table><!----></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>Bastani's PNAS study: same AI, same students, different design.
				Unrestricted access caused 17% harm. Scaffolded access with guardrails
				caused no significant harm.</p> <p>The tool didn't change. The interaction pattern did.</p><!----></div> <!--[--><div class="step-stat svelte-othq90"><span class="stat-value svelte-othq90">17%</span> <span class="stat-label svelte-othq90">worse exam performance with unrestricted AI</span> <!--[--><cite class="stat-source svelte-othq90">Bastani PNAS 2025</cite><!--]--></div><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="cognition" id="cognition"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">Cognitive extensions</h2> <p class="lead svelte-mrcr9q">Your notebook isn't just storage. It's part of how you think.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>Clark and Chalmers (1998) proposed the <strong>extended mind thesis</strong>:
				cognitive processes don't stop at the skull. If the notebook performs
				the same cognitive function as memory, it's part of the cognitive system.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="extended-mind svelte-1rr135g"><svg viewBox="0 0 400 400" class="mind-diagram svelte-1rr135g" aria-label="Extended mind diagram"><circle cx="200" cy="200" r="180" class="ring ring-outer svelte-1rr135g" style="--delay: 400ms"></circle><text x="200" y="35" class="ring-label svelte-1rr135g" style="--delay: 200ms">Environment</text><circle cx="200" cy="200" r="120" class="ring ring-middle svelte-1rr135g" style="--delay: 200ms"></circle><text x="200" y="95" class="ring-label svelte-1rr135g" style="--delay: 100ms">Tools, Notes</text><circle cx="200" cy="200" r="60" class="ring ring-inner svelte-1rr135g" style="--delay: 0ms"></circle><circle cx="200" cy="200" r="24" class="core svelte-1rr135g"></circle><text x="200" y="206" class="core-label svelte-1rr135g">You</text><g class="notebook svelte-1rr135g" transform="translate(280, 180)"><rect x="0" y="0" width="50" height="65" rx="2" class="notebook-cover svelte-1rr135g"></rect><line x1="8" y1="18" x2="42" y2="18" class="notebook-line svelte-1rr135g"></line><line x1="8" y1="28" x2="42" y2="28" class="notebook-line svelte-1rr135g"></line><line x1="8" y1="38" x2="35" y2="38" class="notebook-line svelte-1rr135g"></line><text x="25" y="58" class="notebook-label svelte-1rr135g">Otto's</text></g></svg> <p class="mind-caption svelte-1rr135g">"If the notebook performs the same cognitive function as memory,
		it's part of the cognitive system." <cite class="svelte-1rr135g">— Clark &amp; Chalmers, 1998</cite></p></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p>Applied to AI: every extension in cix isn't a tool you use.
				It's part of the cognitive system the human-AI collaboration forms.
				The <em>design</em> of the extension shapes the <em>nature</em> of the mind.</p> <p class="the-question svelte-mrcr9q">The question isn't "is AI helpful?"<br/> It's <strong class="svelte-mrcr9q">"what kind of mind are you building?"</strong></p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="constraints" id="constraints"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">Design constraints</h2> <p>Not what we believe — what we build and why. Four verifiable constraints,
				each grounded in research, each breaking a specific link in the atrophy loop.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="atrophy-loop svelte-mrcr9q" aria-label="The atrophy loop: tool does work, human stops practicing, can't evaluate output, loses judgment, dependency deepens"><div class="loop-node svelte-mrcr9q">Tool does work</div> <div class="loop-arrow svelte-mrcr9q">→</div> <div class="loop-node svelte-mrcr9q">Human stops practicing</div> <div class="loop-arrow svelte-mrcr9q">→</div> <div class="loop-node svelte-mrcr9q">Can't evaluate output</div> <div class="loop-arrow svelte-mrcr9q">→</div> <div class="loop-node svelte-mrcr9q">Loses judgment</div> <div class="loop-arrow svelte-mrcr9q">→</div> <div class="loop-node svelte-mrcr9q">Dependency deepens</div> <div class="loop-return svelte-mrcr9q">↩</div></div><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><div class="constraints-grid svelte-mrcr9q"><article class="constraint svelte-11ebgn9" style="--stagger-delay: 0ms"><h3 class="constraint-name svelte-11ebgn9">Transparent by Design</h3> <p class="constraint-description svelte-11ebgn9">Extensions expose reasoning, ship docs that teach domain knowledge, show decisions not just outputs.</p> <cite class="constraint-citation svelte-11ebgn9">Blaurock et al., 2025: transparency predicts good collaboration outcomes</cite> <p class="constraint-verification svelte-11ebgn9">Does it log decisions? Do docs explain why, not just what?</p> <span class="constraint-loop svelte-11ebgn9">Breaks: can't evaluate output</span></article><!----> <article class="constraint svelte-11ebgn9" style="--stagger-delay: 150ms"><h3 class="constraint-name svelte-11ebgn9">Evidence-Driven Design</h3> <p class="constraint-description svelte-11ebgn9">Claims backed by data. Extensions prove they work. Build on prior work with attribution.</p> <cite class="constraint-citation svelte-11ebgn9">METR, 2025: 43-point perception gap exists because no one measured</cite> <p class="constraint-verification svelte-11ebgn9">Are claims supported? Is prior work cited? Can effectiveness be measured?</p> <span class="constraint-loop svelte-11ebgn9">Breaks: the illusion that things are working</span></article><!----> <article class="constraint svelte-11ebgn9" style="--stagger-delay: 300ms"><h3 class="constraint-name svelte-11ebgn9">Enable Diversity</h3> <p class="constraint-description svelte-11ebgn9">Forkable, composable, multiple approaches coexist. No single blessed way.</p> <cite class="constraint-citation svelte-11ebgn9">Convergent output research: AI-assisted work converges toward identical solutions</cite> <p class="constraint-verification svelte-11ebgn9">Can it be forked? Do multiple approaches exist in the marketplace?</p> <span class="constraint-loop svelte-11ebgn9">Breaks: tool does work one way forever</span></article><!----> <article class="constraint svelte-11ebgn9" style="--stagger-delay: 450ms"><h3 class="constraint-name svelte-11ebgn9">Require Judgment</h3> <p class="constraint-description svelte-11ebgn9">Extensions defer at decision points. Present choices instead of automating away expertise.</p> <cite class="constraint-citation svelte-11ebgn9">Lee &amp; Bastani, 2025; Kosmyna et al., 2024: passive consumption predicts atrophy</cite> <p class="constraint-verification svelte-11ebgn9">Does it present choices where expertise matters? Does it defer to human judgment?</p> <span class="constraint-loop svelte-11ebgn9">Breaks: dependency deepens</span></article><!----></div><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----> <section class="scrolly-section svelte-tj5z2z" data-scene="goal" id="goal"><!--[!--><!--]--> <div class="scroll-content svelte-tj5z2z"><div class="step svelte-othq90"><div class="step-content svelte-othq90"><h2 class="svelte-mrcr9q">The goal</h2> <blockquote class="svelte-mrcr9q"><p class="svelte-mrcr9q">Think with, not for.</p></blockquote> <p>Every extension in cix is built to these constraints. Not because we believe
				in them abstractly, but because the research shows what happens when you don't.</p><!----></div> <!--[!--><!--]--></div><!----> <div class="step svelte-othq90"><div class="step-content svelte-othq90"><p class="cta svelte-mrcr9q"><a href="./library" class="svelte-mrcr9q">Explore the evidence →</a></p><!----></div> <!--[!--><!--]--></div><!----><!----></div></section><!----></main><!----><!--]--><!----></div> <div class="experimental-tag svelte-12qhfyh" aria-hidden="true">experimental</div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_t0r7ei = {
						base: new URL(".", location).pathname.slice(0, -1),
						assets: "/cix/pr-preview/pr-26"
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("./_app/immutable/entry/start.P5EgdSjT.js"),
						import("./_app/immutable/entry/app.DOouVLp1.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 6],
							data: [null,null],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
