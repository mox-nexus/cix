{"type":"data","nodes":[null,{"type":"data","data":[{"extension":1},{"slug":2,"kind":3,"manifest":4,"tagline":18,"readme":19,"components":20,"variant":23,"tags":10},"data-store","plugin",{"name":2,"version":5,"description":6,"author":7,"license":9,"keywords":10},"0.1.0","Data storage and retrieval patterns. Use when: choosing databases, implementing search, designing hybrid retrieval, selecting embedding models, building RAG systems.",{"name":8},"Yash Vyas","MIT",[11,12,13,14,15,16,17],"storage","retrieval","search","embeddings","vector-db","rag","hybrid-search","Production patterns for storage and retrieval: backends, search, embeddings, RAG.","# data-store\n\nProduction patterns for storage and retrieval: backends, search, embeddings, RAG.\n\n## When to Use\n\n- Choosing storage backend for vectors/search\n- Implementing hybrid search (keyword + semantic)\n- Selecting embedding models\n- Building RAG retrieval layers\n- Personal corpus/knowledge base systems\n\n## Quick Guidance\n\n**Backend selection:**\n- \u003C100K docs → DuckDB, SQLite, LanceDB (embedded)\n- 100K-50M → PostgreSQL + pgvector ← Most apps\n- 50M-1B → Qdrant, Weaviate\n- >1B → Milvus, ClickHouse\n\n**Search mode:**\n- Default to **hybrid (RRF)** — recall improves 0.72 → 0.91 over BM25 alone\n- Use RRF (rank-based), not score blending\n\n**Embedding models:**\n- Personal corpus: Nomic Embed v1.5 (768 dims)\n- Speed-critical: all-MiniLM-L6-v2 (384 dims)\n- Best accuracy: Voyage-4-Large API (1024 dims)\n\n## Skills\n\n| Skill | Use When |\n|-------|----------|\n| `data-store` | Storage selection, search implementation, embedding choices |\n\n## References\n\n- `storage-backends.md` — Backend selection, scaling\n- `search-algorithms.md` — HNSW, IVF, BM25, SPLADE\n- `embedding-models.md` — Model comparison\n- `hybrid-patterns.md` — RRF, re-ranking\n- `rag-architecture.md` — Chunking, CRAG, Self-RAG\n- `duckdb-search.md` — DuckDB FTS/VSS specifics\n",{"agents":21,"skills":22,"hooks":21,"commands":21},0,1,"spark"],"uses":{"params":["slug"]}}]}
