import{a as i,f as n}from"./BKQXIwCx.js";import"./BLJ2k1vR.js";import{y as r}from"./Cfark-2s.js";var a=n('<h1 id="cognitive-effects-evidence">Cognitive Effects Evidence</h1> <p>Research synthesis on how AI collaboration changes human thinking, attention, memory, and metacognitive processes.</p> <hr/> <h2 id="sources">Sources</h2> <ul><li><a href="https://dl.acm.org/doi/10.1145/3613904.3641913" rel="nofollow">Lee et al. (2025). Impact of Generative AI on Critical Thinking. CHI.</a></li> <li><a href="https://www.media.mit.edu/publications/your-brain-on-chatgpt/" rel="nofollow">Kosmyna et al. (2025). Your Brain on ChatGPT: Cognitive Debt. MIT Media Lab.</a></li> <li><a href="https://www.mdpi.com/2075-4698/15/1/6" rel="nofollow">Gerlich (2025). AI Tools and Cognitive Offloading. MDPI Societies.</a></li> <li><a href="https://dl.acm.org/doi/abs/10.1145/3613904.3642699" rel="nofollow">Fernandes et al. (2025). Smarter But None the Wiser. CHI.</a></li> <li><a href="https://academic.oup.com/pnasnexus/article/4/1/pgae558/7939819" rel="nofollow">Lee, D. et al. (2025). The Inversion Scenario. PNAS Nexus.</a></li> <li><a href="https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2025.1510919/full" rel="nofollow">Tomisu et al. (2025). Cognitive Mirror. Frontiers in Education.</a></li></ul> <hr/> <h2 id="the-confidence-competence-inversion">The Confidence-Competence Inversion</h2> <h3 id="lee-et-al-chi-2025-">Lee et al. (CHI 2025) <span class="ev ev-strong" title="CHI peer-reviewed, n=319, structural equation modeling">●</span></h3> <p><strong>Design:</strong> Structural equation modeling with 319 knowledge workers.</p> <p><strong>Key findings:</strong></p> <table><thead><tr><th>Confidence Type</th><th>Effect on Critical Thinking</th><th>Mechanism</th></tr></thead><tbody><tr><td>AI-confidence (trust in AI)</td><td>β = -0.69 (strong negative)</td><td>“AI is reliable” triggers cognitive offloading</td></tr><tr><td>Self-confidence (trust in own judgment)</td><td>β = +0.35 (moderate positive)</td><td>“I can evaluate” maintains engagement</td></tr></tbody></table> <p>The inversion is structural. Higher AI confidence reduces the perceived need for verification. Lower self-confidence reduces the belief that verification would help. Both suppress critical thinking through different mechanisms.</p> <p><strong>The design paradox:</strong> Making AI more accurate and trustworthy increases AI-confidence, which decreases critical thinking, which increases error propagation. Better AI can produce worse outcomes if human engagement collapses.</p> <h3 id="pme-friction-intervention-">PME Friction Intervention <span class="ev ev-strong" title="Same study, controlled experiment">●</span></h3> <p>Lee et al. tested three-component metacognitive friction — Planning, Monitoring, Evaluation:</p> <table><thead><tr><th>Phase</th><th>Intervention</th><th>Effect</th></tr></thead><tbody><tr><td>Planning</td><td>“What’s your approach before I assist?”</td><td>Preserves the generative step</td></tr><tr><td>Monitoring</td><td>“Does this match expectations?”</td><td>Maintains engagement during execution</td></tr><tr><td>Evaluation</td><td>“What would you change next time?”</td><td>Crystallizes learning</td></tr></tbody></table> <p>Three-component friction significantly restored critical thinking that was otherwise suppressed by AI confidence. Single-point friction was insufficient — all three checkpoints were necessary.</p> <p><strong>Limitations:</strong> Cross-sectional design — no longitudinal tracking. β interpretation assumes causality in SEM but the data is observational.</p> <hr/> <h2 id="neural-evidence-for-cognitive-offloading">Neural Evidence for Cognitive Offloading</h2> <h3 id="kosmyna-et-al-mit-media-lab-">Kosmyna et al. (MIT Media Lab) <span class="ev ev-moderate" title="MIT Media Lab EEG study, small sample">◐</span></h3> <p><strong>Design:</strong> EEG measurement during AI-assisted vs unassisted writing.</p> <p><strong>Key findings:</strong></p> <ul><li>Neural connectivity “systematically scaled down” during AI-assisted writing</li> <li>Reduced activation in memory encoding regions</li> <li>Lower engagement in executive function networks</li> <li>Decreased integration between sensory input and long-term storage</li> <li>83.3% of participants couldn’t recall quotes from their own AI-assisted essays</li></ul> <p>The brain treated AI-assisted writing differently from unassisted writing at a physiological level. Information was processed, formatted, submitted — but never encoded as learned knowledge. The episodic memory trace never formed because the deep processing required for encoding never occurred.</p> <p><strong>Limitations:</strong> Small sample size. Single writing domain. EEG has temporal but not spatial precision.</p> <hr/> <h2 id="cognitive-offloading-correlation">Cognitive Offloading Correlation</h2> <h3 id="gerlich-2025-">Gerlich (2025) <span class="ev ev-moderate" title="Survey study, n=666, single source">◐</span></h3> <p><strong>Design:</strong> Survey of 666 participants measuring cognitive offloading and critical thinking.</p> <p><strong>Key findings:</strong></p> <ul><li>r = -0.75 correlation between cognitive offloading and critical thinking</li> <li>r = -0.68 correlation between AI use and critical thinking</li> <li>AI use negatively predicts critical thinking (β = -1.76)</li> <li>Younger users (18-25) showed stronger negative effects than older users (56-65)</li></ul> <p><strong>Age effect hypothesis:</strong> Older users have established cognitive schemas that resist replacement. Younger users building initial schemas are more vulnerable to substitution. If correct, AI exposure during learning phases may have compounding effects — skills never acquired can’t be recovered.</p> <p><strong>Limitations:</strong> Survey-based, self-report. Correlation not causation. Single source.</p> <hr/> <h2 id="metacognition-without-learning">Metacognition Without Learning</h2> <h3 id="fernandes-et-al-chi-2025-">Fernandes et al. (CHI 2025) <span class="ev ev-moderate" title="CHI peer-reviewed, single study">◐</span></h3> <p><strong>Key finding:</strong> “Smarter but none the wiser” — AI users showed improved task performance without improved metacognitive awareness. Performance metrics went up. Metacognitive calibration stayed flat.</p> <p><strong>Mechanism:</strong> AI bypasses desirable difficulties — the productive struggle that builds understanding. Errors force diagnosis. Diagnosis builds mental models. Remove errors, remove learning.</p> <p><strong>Limitations:</strong> Single study. Mechanism inferred from results.</p> <hr/> <h2 id="the-inversion-scenario">The Inversion Scenario</h2> <h3 id="lee-d-et-al-pnas-nexus-2025-">Lee, D. et al. (PNAS Nexus 2025) <span class="ev ev-moderate" title="PNAS Nexus, theoretical model with empirical support">◐</span></h3> <p><strong>Key finding:</strong> A skeptical user with mediocre AI outperforms a credulous user with state-of-the-art AI.</p> <table><thead><tr><th>User Type</th><th>AI Quality</th><th>Outcome</th></tr></thead><tbody><tr><td>High metacognitive sensitivity (skeptical)</td><td>Mediocre</td><td>Catches errors, verifies claims, learns — robust outcomes</td></tr><tr><td>Low metacognitive sensitivity (credulous)</td><td>State-of-the-art</td><td>Accepts outputs uncritically — fragile outcomes</td></tr></tbody></table> <p>Human metacognitive sensitivity matters more than model accuracy. The marginal return to model accuracy diminishes as human engagement drops. Past a threshold, improving the AI makes outcomes worse by suppressing metacognitive processes that catch edge cases.</p> <p><strong>Limitations:</strong> Theoretical model with limited empirical validation. The exact threshold is unknown.</p> <hr/> <h2 id="the-cognitive-mirror">The Cognitive Mirror</h2> <h3 id="tomisu-et-al-frontiers-in-education-2025-">Tomisu et al. (Frontiers in Education, 2025) <span class="ev ev-moderate" title="Frontiers in Education, single study">◐</span></h3> <p><strong>Technique:</strong> Reflecting the human’s reasoning back with structured questions rather than providing answers.</p> <p>The pattern forces articulation (makes implicit explicit) → evaluation (metacognitive monitoring) → gap discovery (generative learning). Instead of “here’s the solution,” the interaction becomes “here’s what I see in your reasoning — what am I missing?”</p> <p><strong>Mechanism:</strong> Making implicit reasoning explicit activates metacognitive monitoring. Humans notice flaws in their own logic when forced to explain it. AI-generated solutions bypass this entirely.</p> <p><strong>Limitations:</strong> Qualitative study. Effect size not quantified.</p> <hr/> <h2 id="the-caim-framework">The CAIM Framework</h2> <p>Multiple studies converged on the Collaborative AI Metacognition (CAIM) scale measuring four dimensions:</p> <table><thead><tr><th>Dimension</th><th>Definition</th><th>Why It Matters</th></tr></thead><tbody><tr><td>Understanding</td><td>Knowing AI capabilities and limits</td><td>Calibrates expectations</td></tr><tr><td>Use</td><td>Choosing when to engage AI</td><td>Prevents inappropriate delegation</td></tr><tr><td>Evaluation</td><td>Assessing output quality</td><td>Error detection</td></tr><tr><td>Ethics</td><td>Recognizing implications</td><td>Long-term judgment</td></tr></tbody></table> <p>Traditional AI design optimizes for Use — making the tool easy to invoke. But Understanding, Evaluation, and Ethics are what prevent cognitive collapse.</p> <hr/> <h2 id="evidence-summary">Evidence Summary</h2> <table><thead><tr><th>Finding</th><th>Effect Size</th><th>Evidence Level</th><th>Source</th></tr></thead><tbody><tr><td>AI confidence → less critical thinking</td><td>β = -0.69</td><td><span class="ev ev-strong">●</span> Strong</td><td>Lee et al. CHI 2025</td></tr><tr><td>Self-confidence → more critical thinking</td><td>β = +0.35</td><td><span class="ev ev-strong">●</span> Strong</td><td>Lee et al. CHI 2025</td></tr><tr><td>PME friction restores engagement</td><td>Significant</td><td><span class="ev ev-strong">●</span> Strong</td><td>Lee et al. CHI 2025</td></tr><tr><td>Neural connectivity reduced with AI</td><td>Measured via EEG</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Kosmyna, MIT</td></tr><tr><td>83.3% recall failure</td><td>83.3%</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Kosmyna, MIT</td></tr><tr><td>Cognitive offloading ↔ critical thinking</td><td>r = -0.75</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Gerlich 2025</td></tr><tr><td>Younger users more affected</td><td>Age-stratified</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Gerlich 2025</td></tr><tr><td>Performance up, metacognition flat</td><td>Observed</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Fernandes CHI 2025</td></tr><tr><td>Skeptical user + weak AI > credulous + strong AI</td><td>Model prediction</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Lee D., PNAS Nexus</td></tr><tr><td>Cognitive mirror preserves learning</td><td>Qualitative</td><td><span class="ev ev-moderate">◐</span> Moderate</td><td>Tomisu 2025</td></tr><tr><td>Long-term developer capability trajectory</td><td>Unknown</td><td><span class="ev ev-speculative">◌</span> Speculative</td><td>No direct study</td></tr></tbody></table> <hr/> <h2 id="the-unsolved-question">The Unsolved Question</h2> <p>No longitudinal study tracks developer capability decline over extended AI use. We have 3-month medical studies showing 20% skill loss (<a href="skill-formation-evidence">skill formation evidence →</a>). We have cross-sectional developer data showing perception gaps and reduced critical thinking. But the multi-year trajectory remains unknown.</p> <p>The research we need: cohort study tracking developers’ unassisted capability over 2-5 years of varied AI use. Until that exists, we’re inferring from adjacent domains and short-term experiments.</p> <hr/> <p><em>Full citations in <a href="bibliography">bibliography</a></em></p>',1);function l(e){var t=a();r(134),i(e,t)}export{l as default};
