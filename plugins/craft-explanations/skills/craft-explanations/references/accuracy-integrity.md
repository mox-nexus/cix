# Accuracy and Intellectual Integrity

Teaching effectiveness means nothing if the content is wrong. Verification precedes craft.

## Why Accuracy Is Foundational

Teaching creates an asymmetric trust relationship. The learner is vulnerable — they don't know what they don't know. Wrong information has compounding costs:

| Cost | Mechanism |
|------|-----------|
| **Compounding error** | Wrong foundations lead to wrong conclusions lead to wrong decisions |
| **Unlearning difficulty** | First impressions persist; correction requires more effort than initial learning |
| **Credibility collapse** | When errors discovered, everything you taught becomes suspect |
| **Downstream spread** | Learners cite, build on, and pass on what you taught |

## Common Failure Modes

| Failure | Example | Fix |
|---------|---------|-----|
| **Inference as finding** | "Study shows X causes Y" when study showed correlation | State what was actually measured |
| **Selective citation** | Cherry-picking studies that support your view | Acknowledge contradictory evidence |
| **Mechanism invention** | "This works because..." when mechanism unknown | Say "correlates with" not "causes" |
| **Implication overreach** | Drawing conclusions evidence doesn't support | Separate findings from interpretation |
| **Framing bias** | Presenting values as facts | Label philosophy as philosophy |

## The Accuracy Test

Before teaching anything:

1. **What was actually found?** — Not what you infer, what was measured
2. **What's the evidence quality?** — Sample size, methodology, replication
3. **What are you adding?** — Distinguish source claims from your interpretation
4. **Would an honest skeptic accept this framing?** — If not, revise

## Evidence Labeling

Be explicit about evidence strength:

| Level | Description | Language |
|-------|-------------|----------|
| **Strong** | Meta-analyses, replications | "Research consistently shows..." |
| **Moderate** | Several studies | "Studies suggest..." |
| **Weak** | Single study | "One study found..." |
| **Speculative** | Theory only | "In principle..." |

## Chain of Verification (CoVe)

Draft, then question, then check, then refine. (Dhuliawala et al. 2023: +23% accuracy)

| Step | For teaching claims |
|------|---------------------|
| **Draft** | State the claim you're about to teach |
| **Question** | What was measured? Correlation or causation? Effect size? Replicated? Counter-evidence? |
| **Check** | Answer each question honestly, without defending the claim |
| **Refine** | Update claim based on answers |

## Decomposition

Break complex claims into atomic sub-claims. Verify each independently.

| Complex claim | Sub-claims | Verification |
|---------------|------------|--------------|
| "AI collaboration enhances capability" | 1. AI + human outperforms human alone | In what tasks? What metrics? |
| | 2. Human learns from collaboration | Was learning measured, or just performance? |
| | 3. Enhancement persists after AI removed | Was transfer tested? |

If any sub-claim fails verification, the complex claim fails.

## The Pre-Teaching Check

1. **Can I pass CoVe?** — If verification questions expose gaps, not ready
2. **Can I decompose it?** — If I can't break it down, I don't understand it
3. **What's my evidence level?** — Label honestly
4. **Would a skeptic accept this?** — If not, revise

Teaching wrong things effectively is worse than not teaching at all.

---

**Sources**: Dhuliawala et al. (2024) Chain-of-Verification Reduces Hallucination, ACL. Accuracy and intellectual integrity practices from scientific communication standards.
