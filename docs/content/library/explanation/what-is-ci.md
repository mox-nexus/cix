# What is Collaborative Intelligence?

Most AI interactions go like this: you ask, it answers, you move on — useful, fast, and entirely one-directional. The loop doesn't require your reasoning to be good, your understanding to deepen, or either side to be shaped by what the other brings.

That's not collaborative intelligence.

---

## Three criteria

The most rigorous definition comes from a 2024 scoping review of 1,250 AI applications (Schleiger et al., *Applied Artificial Intelligence*). An interaction qualifies as collaborative intelligence only if all three hold:

1. **Complementarity** — the collaboration produces outcomes beyond what either party could achieve alone
2. **Shared objective** — human and AI working toward the same goal
3. **Sustained two-way interaction** — bidirectional exchange over time, not a one-shot query-response

The finding: **16 of 1,250 applications met all three criteria.**

Most of what we call "AI tools" isn't CI by any serious definition. It's AI assistance — fast, useful, one-directional. The human directs, the AI executes — valuable, but not collaboration.

---

## Substitutive vs. collaborative

The operative distinction isn't human versus AI. It's substitutive versus collaborative — and it's entirely a matter of interaction design.

52 engineers. Same tool. Same timeframe. Mastery scores at the end ranged from 24% to 86% (Shen & Tamkin, Anthropic, 2026 — randomized controlled trial).

The difference wasn't ability. It was interaction pattern. Engineers who used AI to generate code and then asked follow-up questions scored 86%. Engineers who delegated and moved on scored 39%. The gap opened across four extra minutes of comprehension per session.

A parallel study put 1,000 physics students with AI tutors designed two ways — one that answered directly, one that asked guiding questions. Direct answers produced 17% worse performance on unassisted assessments (Bastani et al., PNAS 2025). Same technology, different interaction design, opposite outcomes.

| Substitutive | Collaborative |
|---|---|
| AI does the work, human approves | AI amplifies, human remains central |
| "Here's the answer" | "Here's how to think about this" |
| Trust becomes accept/reject | Trust becomes informed evaluation |
| Skills erode from disuse | Skills compound through use |

---

## The GPS effect

Drivers who rely on GPS fail to build spatial maps of their city. The navigation is accurate. The driver gets there. But the mental model — the thing that lets you navigate when GPS fails, notice shortcuts, understand the city as a structure — never forms. The capability being outsourced wasn't "knowing the right turn." It was the map.

Developers who rely on AI to generate solutions face the same dynamic. The code compiles. The PR ships. But the mental model of the codebase — the thing that lets you architect the next system, debug the hard problem, notice the design smell — doesn't form, or dissolves. What's being outsourced isn't "writing the for loop." It's the map.

CI isn't a rejection of navigation tools. It's a design position: use the tool in ways that build the map, not bypass it.

---

## Why defaults matter

The studies don't show that developers are careless. They show that default AI interaction patterns reliably produce substitutive outcomes, and that's upstream of individual behavior.

When an AI returns a complete answer, the path of least resistance is to accept it. When it returns a question that guides your thinking, the path of least resistance is to think. The design of the interaction shapes the cognitive pattern, not the user's intent.

Anthropic's Economic Index tracked this at scale: by late 2024, automation usage (AI does the task) had surpassed augmentation usage (AI amplifies the human) for the first time. The default was winning. Collaborative intelligence names what you have to build deliberately against it — which requires a different interaction structure, not a better model.

---

## The evaluation

An interaction is collaborative when both participants come out more capable than before: the human's reasoning sharpened by the exchange, the AI's response shaped by what the human brought, the output something neither would have reached alone.

That's also the diagnostic. Does this interaction build the map, or replace it? Does it require the human's reasoning to be good, or route around it?

For most AI tools, the default answer is: replace and route around.
