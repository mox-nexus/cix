<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		
		<link href="../_app/immutable/assets/0.04mfEt8Y.css" rel="stylesheet">
		<link href="../_app/immutable/assets/CrossLinks.C4T6atsV.css" rel="stylesheet">
		<link href="../_app/immutable/assets/5.Bnuf7QZ4.css" rel="stylesheet">
		<link rel="modulepreload" href="../_app/immutable/entry/start.D5y4usZ1.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/CEnrcVot.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/iyO_HpW3.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/_cEvoN5f.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/D0iwhpLH.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Bhs-_H7e.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/Cs0QLTHR.js">
		<link rel="modulepreload" href="../_app/immutable/entry/app.zelJeFlp.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BPYyHSBz.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/2hgU3PCP.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/C4-dLuTv.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/_Dz5Oby6.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DtLL33Bf.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/a8oTfHeT.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/CFsY3MpS.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/0.BxL1EdFy.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BwsKPAvP.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BbhyhsYm.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/DZr9k4L0.js">
		<link rel="modulepreload" href="../_app/immutable/nodes/5.yOPt9Hj_.js">
		<link rel="modulepreload" href="../_app/immutable/chunks/BFxfVKZg.js"><!--12qhfyh--><meta name="description" content="Extensions that enhance human capability, not replace it."/><!----><!--wzm642--><meta name="description" content="Extended memory for you and your agents. Excavates and connects historical human-AI collaboration artifacts across heterogeneous sources."/><!----><title>memex — cix</title>
	</head>
	<body data-sveltekit-preload-data="hover">
		<div style="display: contents"><!--[--><!--[--><!----><a href="#main" class="skip-link">Skip to content</a> <!--[--><nav class="site-nav svelte-qgym72" aria-label="Site navigation"><a href="../" class="nav-wordmark svelte-qgym72">cix</a> <div class="nav-links svelte-qgym72"><!--[--><a href="../ethos" class="nav-link svelte-qgym72">ethos</a><a href="../catalog" class="nav-link svelte-qgym72">catalog</a><a href="../library" class="nav-link svelte-qgym72">library</a><!--]--></div></nav><!--]--> <div class="page svelte-12qhfyh has-nav"><!--[!--><!----><main id="main" class="detail-page svelte-wzm642" style="--variant-color: var(--spark-core)"><nav class="detail-back svelte-wzm642"><a href="../catalog" class="svelte-wzm642">← catalog</a></nav> <header class="detail-header svelte-wzm642"><div class="header-top svelte-wzm642"><h1 class="svelte-wzm642">memex</h1> <span class="detail-kind svelte-wzm642">tool</span> <span class="detail-version svelte-wzm642">0.2.0</span></div> <p class="detail-description svelte-wzm642">Extended memory for you and your agents. Excavates and connects historical human-AI collaboration artifacts across heterogeneous sources.</p> <!--[!--><!--]--> <!--[--><div class="detail-tags svelte-wzm642"><!--[--><span class="tag svelte-wzm642">tool</span><span class="tag svelte-wzm642">cli</span><!--]--></div><!--]--></header> <!--[--><nav class="detail-tabs svelte-wzm642" role="tablist"><!--[--><button role="tab" class="tab svelte-wzm642 active" aria-selected="true">README <!--[!--><!--]--></button><button role="tab" class="tab svelte-wzm642" aria-selected="false">Explanation <!--[--><span class="tab-count svelte-wzm642">2</span><!--]--></button><button role="tab" class="tab svelte-wzm642" aria-selected="false">How-To <!--[--><span class="tab-count svelte-wzm642">2</span><!--]--></button><!--]--></nav><!--]--> <article class="detail-content svelte-wzm642 prose"><!--[--><!----><h1>Memex</h1>
<p>Excavating Collaborative Intelligence Artifacts.</p>
<h2>Usage</h2>
<pre><code class="language-bash"># Ingest a Claude.ai export
memex ingest ~/Downloads/claude-export.json

# Search the corpus
memex dig &quot;auth implementation&quot;

# View corpus stats
memex corpus

# Raw SQL (power-user)
memex query &quot;SELECT COUNT(*) FROM fragments&quot;
memex sql  # Interactive shell
</code></pre>
<h2>Storage</h2>
<p>Corpus is stored at <code>~/.memex/corpus.duckdb</code>.</p>
<!----><!--]--></article></main><!----><!--]--><!----></div> <div class="experimental-tag svelte-12qhfyh" aria-hidden="true">experimental</div><!----><!--]--> <!--[!--><!--]--><!--]-->
			
			<script>
				{
					__sveltekit_14cdtw8 = {
						base: new URL("..", location).pathname.slice(0, -1),
						assets: "/cix"
					};

					const element = document.currentScript.parentElement;

					Promise.all([
						import("../_app/immutable/entry/start.D5y4usZ1.js"),
						import("../_app/immutable/entry/app.zelJeFlp.js")
					]).then(([kit, app]) => {
						kit.start(app, element, {
							node_ids: [0, 5],
							data: [null,{type:"data",data:{extension:{slug:"memex",kind:"tool",manifest:{name:"memex",version:"0.2.0",description:"Extended memory for you and your agents. Excavates and connects historical human-AI collaboration artifacts across heterogeneous sources.",author:{name:"Mox Labs"}},tagline:"Excavating Collaborative Intelligence Artifacts.",readme:"# Memex\n\nExcavating Collaborative Intelligence Artifacts.\n\n## Usage\n\n```bash\n# Ingest a Claude.ai export\nmemex ingest ~/Downloads/claude-export.json\n\n# Search the corpus\nmemex dig \"auth implementation\"\n\n# View corpus stats\nmemex corpus\n\n# Raw SQL (power-user)\nmemex query \"SELECT COUNT(*) FROM fragments\"\nmemex sql  # Interactive shell\n```\n\n## Storage\n\nCorpus is stored at `~/.memex/corpus.duckdb`.\n",components:{agents:0,skills:0,hooks:0,commands:0},variant:"spark",tags:["tool","cli"],docs:{explanation:[{slug:"methodology",title:"Memex: Methodology",content:"# Memex: Methodology\n\nWhy memex exists and how it's designed.\n\n---\n\n## Contents\n\n- [The Problem](#the-problem)\n- [Bush's Vision](#bushs-vision)\n- [Design Decisions](#design-decisions)\n- [Hybrid Search Architecture](#hybrid-search-architecture)\n- [The Fragment as Unit of Recovery](#the-fragment-as-unit-of-recovery)\n- [Convention Over Configuration](#convention-over-configuration)\n- [Hexagonal Architecture](#hexagonal-architecture)\n- [What Memex Is Not](#what-memex-is-not)\n\n---\n\n## The Problem\n\nHuman-AI collaboration generates artifacts: conversations, decisions, reasoning traces, design explorations. These accumulate across platforms (Claude, ChatGPT, Gemini) and sessions. Within weeks, the volume makes retrieval difficult. Within months, critical context is effectively lost.\n\nThe cost is real. Teams re-derive decisions that were already made. Reasoning that led to architectural choices evaporates. The same questions get asked and re-answered because the original exchange is buried in an export file no one can search.\n\n**This is the excavation problem.** The artifacts exist. Finding them is the bottleneck.\n\n---\n\n## Bush's Vision\n\nVannevar Bush described the memex in \"As We May Think\" (The Atlantic, 1945) as \"an enlarged intimate supplement to memory.\" His insight wasn't about storage -- it was about **associative trails**: the ability to link related ideas across a personal knowledge corpus and follow those connections later.\n\nBush was writing about physical media (microfilm, mechanical selectors), but the core problem he identified persists: human memory is associative, not indexed. We remember that we discussed authentication *somewhere*, not the date, platform, or conversation ID. A useful retrieval system must bridge this gap.\n\nMemex implements Bush's vision with modern tools:\n\n| Bush's Concept | Memex Implementation |\n|----------------|---------------------|\n| Personal knowledge corpus | DuckDB-backed fragment store |\n| Associative trails | FOLLOWS edges between fragments |\n| Selection by content | Hybrid search (BM25 + semantic + reranking) |\n| Intimate supplement | Local-first, convention-over-config |\n\n---\n\n## Design Decisions\n\n### Excavation, Not Observation\n\nMemex operates on **historical artifacts** -- conversations and reasoning traces that already happened. It does not stream, watch, or observe live interactions. This is a deliberate scope constraint:\n\n- Live observation requires persistent processes, event streams, and real-time indexing\n- Historical excavation requires only ingestion and search\n- The two are architecturally different problems\n\nConflating them produces a tool that does both poorly. Memex does excavation well.\n\n### Local-First\n\nAll data stays on the user's machine. No cloud sync, no remote API calls for search. The embedding model (nomic-embed-text-v1.5) and cross-encoder reranker (MS MARCO MiniLM) run locally via ONNX.\n\n**Why:** Collaboration artifacts contain sensitive context -- strategic decisions, security discussions, personnel conversations. Sending these to external services for search indexing is a non-starter for many users.\n\n### Defaults for Most, Complexity for Few\n\n```\nmemex dig \"where did I decide on auth?\"     # 80% case: hybrid search\nmemex query \"SELECT * FROM fragments ...\"    # 20% case: SQL escape hatch\n```\n\nThe `dig` command is the primary interface. It combines BM25 keyword search, semantic embedding search, and cross-encoder reranking. Users don't need to understand any of that -- they type a query, get results.\n\nThe SQL escape hatch exists for power users who need complex filtering, aggregation, or ad hoc analysis. DuckDB's analytical SQL is available directly.\n\n---\n\n## Hybrid Search Architecture\n\nSingle search modalities have known limitations:\n\n| Modality | Strength | Weakness |\n|----------|----------|----------|\n| **Keyword (BM25)** | Exact term matching, fast | Misses synonyms, paraphrases |\n| **Semantic (embeddings)** | Conceptual similarity | Misses exact terms, \"dilutes\" precision |\n| **Cross-encoder reranking** | Pair-level relevance scoring | Too slow for full-corpus search |\n\nMemex combines all three via Reciprocal Rank Fusion (RRF):\n\n1. **BM25** retrieves keyword-matching fragments from DuckDB's full-text search index\n2. **Semantic search** retrieves conceptually similar fragments via HNSW vector index\n3. **RRF** (k=60) fuses the two ranked lists into a single ordering\n4. **Cross-encoder** reranks the fused top-N for final relevance scoring\n\nThis pipeline means `memex dig \"OAuth2 implementation\"` finds fragments that:\n- Contain the exact term \"OAuth2\" (BM25)\n- Discuss authentication concepts without using that term (semantic)\n- Are ranked by actual query-fragment relevance (cross-encoder)\n\n### Why RRF Over Learned Fusion\n\nReciprocal Rank Fusion (Cormack et al., 2009) is a parameter-free fusion method. It doesn't require training data or tuning -- it works by reciprocal rank combination.\n\nFor a personal knowledge tool where the corpus varies dramatically per user, a training-free fusion method is the right choice. There's no representative training set for \"all possible personal knowledge corpora.\"\n\n---\n\n## The Fragment as Unit of Recovery\n\nThe atomic entity in memex is the **Fragment** -- a self-contained unit of collaborative intelligence. Not a message (too small, lacks context), not a full conversation (too large, buries signal).\n\nFragments are extracted during ingestion. Each carries:\n- **Content**: The actual text\n- **Provenance**: Where it came from (source_kind, source_id, timestamp)\n- **Embedding**: Vector representation for semantic search\n- **FOLLOWS edges**: Links to chronologically adjacent fragments\n\nThe fragment granularity is a design decision with consequences:\n\n| Granularity | Search Quality | Storage Cost | Context |\n|-------------|---------------|-------------|---------|\n| Message-level | Noisy (too many tiny hits) | Low | Lost (single turn) |\n| Fragment-level | Balanced | Moderate | Preserved (coherent unit) |\n| Conversation-level | Few results, hard to scan | High | Complete but overwhelming |\n\n---\n\n## Convention Over Configuration\n\nMemex uses `.memex/` directories like `.git/` -- walk up from CWD to find the active workspace.\n\n```\n~/.memex/           # Global workspace (default)\nproject/.memex/     # Project-local workspace (overrides global)\n```\n\n**No flags needed.** If you're in a project with `.memex/`, memex uses that store. If not, it falls back to global. This is the same mental model as git: you don't pass `--repo` flags, you work in a directory and git finds the repo.\n\nThe precedence order:\n1. `MEMEX_*` environment variables (explicit override)\n2. Local `.memex/` (walk up from CWD)\n3. Global `~/.memex/config.toml`\n4. Defaults\n\n---\n\n## Hexagonal Architecture\n\nMemex follows hexagonal architecture (ports and adapters) to separate concerns:\n\n**Domain**: Pure business logic with no external dependencies. Fragment, Provenance, EmbeddingConfig are plain models. ExcavationService orchestrates use cases through port interfaces.\n\n**Ports**: Protocol-based interfaces (`typing.Protocol` with `@runtime_checkable`). Four driven ports:\n- `CorpusPort` -- persistence and search\n- `EmbeddingPort` -- vector generation\n- `RerankerPort` -- cross-encoder reranking\n- `SourceAdapterPort` -- format-specific ingestion\n\n**Adapters**: Concrete implementations. DuckDB for corpus, fastembed for embeddings, Rich+Click for CLI.\n\n**Why this matters for users:** The architecture means memex can swap components without changing behavior. A new embedding model, a different storage engine, or an additional source format (Gemini, custom) requires one new adapter -- zero domain changes.\n\n---\n\n## What Memex Is Not\n\nPrecision in scope prevents scope creep:\n\n| Memex Is | Memex Is Not |\n|----------|-------------|\n| Historical artifact excavation | Live session observation |\n| Personal knowledge retrieval | Team knowledge management |\n| Source-agnostic search | Claude-specific tooling |\n| Local-first | Cloud-synced |\n| CLI-first | GUI application |\n\nThe boundaries are deliberate. Each \"is not\" represents a different tool with different architecture. Trying to be all of them produces none of them well.\n"},{slug:"sources",title:"Sources",content:"# Sources\n\nResearch and technical foundations behind memex.\n\n---\n\n## Research Synthesis\n\nThe path from Vannevar Bush's associative trails to computational hybrid search required five converging advances: full-text indexing (BM25, 1994), dense retrieval (DPR, 2020), efficient vector storage (HNSW/DuckDB-VSS), cross-encoder reranking (MiniLM, 2020), and rank fusion (RRF, 2009). Memex combines all five into a single local-first tool because no single retrieval method handles the range of queries humans actually ask about their own work.\n\n---\n\n## Foundational Vision\n\n**Bush, V. (1945). \"As We May Think.\" The Atlantic Monthly, 176(1), 101-108.**\n\nThe original memex concept: a device for storing, linking, and retrieving personal knowledge via associative trails. Bush argued that human memory is associative, not indexed -- and that retrieval tools should match this cognitive pattern.\n\n**Relevance to memex:** The `dig` command implements associative retrieval. FOLLOWS edges between fragments implement trails. The entire tool is named after Bush's vision.\n\n---\n\n## Search and Retrieval\n\n**Robertson, S.E., & Zaragoza, H. (2009). \"The Probabilistic Relevance Framework: BM25 and Beyond.\" Foundations and Trends in Information Retrieval, 3(4), 333-389.**\n\nThe foundational probabilistic retrieval model. BM25 remains the dominant keyword search algorithm after decades because it handles term frequency saturation and document length normalization correctly.\n\n**Relevance to memex:** BM25 powers the keyword search channel in hybrid search, via DuckDB's full-text search extension.\n\n---\n\n**Karpukhin, V., et al. (2020). \"Dense Passage Retrieval for Open-Domain Question Answering.\" EMNLP 2020.**\n\nDemonstrated that dense (embedding-based) retrieval can outperform BM25 for question-answering tasks where semantic matching matters more than exact keyword overlap.\n\n**Relevance to memex:** Motivates the semantic search channel. When users search for \"authentication decisions\" they want fragments about auth even if the exact word \"authentication\" doesn't appear.\n\n---\n\n**Cormack, G.V., Clarke, C.L.A., & Buettcher, S. (2009). \"Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods.\" SIGIR 2009.**\n\nRRF is a simple, parameter-free method for combining multiple ranked lists. With k=60, it consistently outperforms more complex learned fusion methods.\n\n**Relevance to memex:** RRF fuses BM25 and semantic search results. Its parameter-free nature is critical -- there's no representative training corpus for personal knowledge retrieval.\n\n---\n\n**Nogueira, R., & Cho, K. (2019). \"Passage Re-ranking with BERT.\" arXiv:1901.04085.**\n\nCross-encoder reranking -- feeding query-document pairs through a transformer -- achieves higher relevance accuracy than bi-encoder retrieval alone. The tradeoff is computational cost (quadratic in candidates).\n\n**Relevance to memex:** The cross-encoder reranker (MS MARCO MiniLM-L-6-v2) runs on the top-N fused results, not the full corpus. This makes it practical for local use.\n\n---\n\n## Embedding Models\n\n**Nussbaum, Z., Morris, J., Duderstadt, B., & Mulyar, A. (2024). \"Nomic Embed: Training a Reproducible Long Context Text Embedder.\" Nomic AI Technical Report.**\n\nnomic-embed-text-v1.5 produces 768-dimensional embeddings with Matryoshka support (can truncate to 256/512 dims). Fully open-source weights and training data.\n\n**Relevance to memex:** Default embedding model. Runs locally via fastembed (ONNX runtime), no GPU required. Chosen for: open weights, reproducibility, long-context support (8192 tokens), and local inference.\n\n---\n\n## Storage\n\n**Raasveldt, M., & Muhleisen, H. (2019). \"DuckDB: An Embeddable Analytical Database.\" SIGMOD 2019.**\n\nDuckDB is an in-process analytical database optimized for OLAP workloads. Embeddable (no server), column-oriented, with extensions for full-text search (FTS) and vector similarity search (VSS).\n\n**Relevance to memex:** Single-file corpus (`corpus.duckdb`) with both BM25 (FTS extension) and HNSW vector index (VSS extension). No external services needed. The embeddable nature enables the local-first, convention-over-config design.\n\n---\n\n## Hexagonal Architecture\n\n**Cockburn, A. (2005). \"Hexagonal Architecture (Ports and Adapters).\" alistair.cockburn.us.**\n\nThe original articulation of ports and adapters: domain logic depends on abstract interfaces (ports), with concrete implementations (adapters) injected at composition time.\n\n**Relevance to memex:** The architecture enables testing without infrastructure (in-memory adapters) and component swapping without domain changes (new embedding model = one adapter).\n\n---\n\n## Protocol-Based Ports\n\n**Python Enhancement Proposal 544. \"Protocols: Structural subtyping (static duck typing).\" Python 3.8+.**\n\n`typing.Protocol` enables structural subtyping -- any class implementing the right methods satisfies the protocol without inheritance. Combined with `@runtime_checkable`, provides interface enforcement without coupling.\n\n**Relevance to memex:** All four driven ports (CorpusPort, EmbeddingPort, RerankerPort, SourceAdapterPort) use Protocol. This was a deliberate arch-guild decision: Protocol over ABC for hexagonal ports in Python.\n\n---\n\n## Cross-Encoder Reranking\n\n**Wang, W., Wei, F., Dong, L., Bao, H., Yang, N., & Zhou, M. (2020). \"MiniLM: Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers.\" NeurIPS 2020.**\n\nKnowledge distillation from large transformers to compact models. MiniLM-L-6-v2 retains most of BERT-base's effectiveness at a fraction of the size.\n\n**Relevance to memex:** The cross-encoder reranker uses MS MARCO fine-tuned MiniLM-L-6-v2. Small enough for local inference, effective enough for reranking.\n\n---\n\n## Collaborative Intelligence Context\n\n**Hemmer, P., Schemmer, M., Riefle, L., Vossing, M., & Kuehl, N. (2024). \"Complementarity in Human-AI Collaboration.\" European Journal of Information Systems.**\n\nComplementary AI design -- where human and AI capabilities combine to exceed either alone -- requires that the human remain actively engaged. Substitutive designs (AI does the work) produce dependency.\n\n**Relevance to memex:** Memex is a retrieval tool, not a synthesis tool. It surfaces fragments for the human to interpret, connect, and act on. The human does the thinking; memex does the finding.\n"}],"how-to":[{slug:"configure-local-store",title:"How to Configure a Local Store",content:"# How to Configure a Local Store\n\nSet up a project-specific memex corpus separate from your global store.\n\n---\n\n## Setup\n\nFrom your project root:\n\n```bash\ncd ~/myproject\nmemex init --local\n```\n\nThis creates a `.memex/` directory:\n\n```\nmyproject/\n├── .memex/\n│   ├── config.toml       # Optional local config overrides\n│   └── corpus.duckdb     # Project-local corpus\n├── src/\n└── ...\n```\n\nAdd `.memex/` to your `.gitignore`:\n\n```bash\necho '.memex/' >> .gitignore\n```\n\n---\n\n## How Resolution Works\n\nMemex walks up from your current working directory looking for `.memex/`. This means subdirectories inherit the project store:\n\n```bash\ncd ~/myproject/src/lib\nmemex dig \"auth\"           # Uses ~/myproject/.memex/\n\ncd ~/otherproject\nmemex dig \"auth\"           # Uses ~/.memex/ (global fallback)\n```\n\nNo flags needed. The convention handles routing automatically.\n\n---\n\n## Ingesting Into a Local Store\n\nWhen a local `.memex/` exists, `memex ingest` writes to it:\n\n```bash\ncd ~/myproject\nmemex ingest relevant-conversations.json    # Goes to .memex/corpus.duckdb\n```\n\nTo ingest into the global store instead, work from a directory without `.memex/`:\n\n```bash\ncd ~\nmemex ingest all-conversations.json         # Goes to ~/.memex/corpus.duckdb\n```\n\n---\n\n## Checking Which Store Is Active\n\n```bash\nmemex status\n```\n\nThis shows the active corpus path, fragment count, and capabilities. Use it to confirm which store memex is using.\n\n---\n\n## Override With Environment Variables\n\nFor scripts or one-off commands, override the store with `MEMEX_CORPUS_PATH`:\n\n```bash\nMEMEX_CORPUS_PATH=~/special/corpus.duckdb memex dig \"query\"\n```\n\nEnvironment variables have highest precedence, overriding both local `.memex/` and global config.\n"},{slug:"ingest-conversations",title:"How to Ingest Conversations",content:"# How to Ingest Conversations\n\nImport conversation exports from Claude.ai and ChatGPT into your memex corpus.\n\n---\n\n## Claude.ai Export\n\n1. Go to [claude.ai/settings](https://claude.ai/settings)\n2. Request a data export (arrives as a `.zip` or `.json`)\n3. Ingest:\n\n```bash\nmemex ingest ~/Downloads/claude-export.json\n```\n\nMemex auto-detects the Claude conversation format and extracts fragments with provenance metadata (timestamps, conversation IDs).\n\n### Large Exports\n\nFor large exports (1000+ conversations), ingest without embeddings first, then backfill:\n\n```bash\nmemex ingest ~/Downloads/claude-export.json --no-embed\nmemex backfill\n```\n\nThis separates the I/O-bound ingestion from the CPU-bound embedding generation, and shows progress for each phase independently.\n\n---\n\n## ChatGPT Export\n\n1. Go to ChatGPT Settings > Data Controls > Export Data\n2. Download the export (arrives as a `.zip` containing `conversations.json`)\n3. Extract and ingest:\n\n```bash\nunzip chatgpt-export.zip\nmemex ingest conversations.json\n```\n\nThe OpenAI source adapter handles the ChatGPT conversation format.\n\n---\n\n## Verifying Ingestion\n\nAfter ingesting, check corpus stats:\n\n```bash\nmemex corpus\n```\n\nThis shows total fragments, source breakdown, and embedding coverage. If embedding coverage is below 100%, run `memex backfill` to generate missing embeddings.\n\n---\n\n## Multiple Sources\n\nYou can ingest from multiple platforms into the same corpus. Memex tracks provenance per fragment, so search results show where each fragment came from:\n\n```bash\nmemex ingest ~/Downloads/claude-export.json\nmemex ingest ~/Downloads/chatgpt-conversations.json\nmemex dig \"authentication decisions\"   # Searches across both\n```\n\n---\n\n## Re-ingestion\n\nMemex deduplicates by source ID. Re-ingesting the same export is safe -- existing fragments are skipped, new ones are added.\n\n```bash\n# Safe to run multiple times\nmemex ingest ~/Downloads/claude-export-v2.json\n```\n"}],tutorials:[]},docCount:4}},uses:{params:["slug"]}}],
							form: null,
							error: null
						});
					});
				}
			</script>
		</div>
	</body>
</html>
